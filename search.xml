<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【Java】Java GC相关问题]]></title>
    <url>%2F2021%2F03%2F15%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FJVM%2F</url>
    <content type="text"><![CDATA[JVM gc 什么样的对象会从新生代到老年代 新生代的垃圾回收算法 老年代的垃圾回收算法 常用的GC算法]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2021%2F03%2F11%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Spring】SpringBean生命周期]]></title>
    <url>%2F2020%2F10%2F22%2FSpring%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2FSpringBean%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%2F</url>
    <content type="text"><![CDATA[注册阶段 合并阶段 实例化阶段 初始化阶段 销毁阶段 Bean 的生命周期如上图所示，Bean 的生命周期还是比较复杂的，下面来对上图每一个步骤做文字描述: Spring启动，查找并加载需要被Spring管理的bean，进行Bean的实例化 Bean实例化后对将Bean的引入和值注入到Bean的属性中 如果Bean实现了BeanNameAware接口的话，Spring将Bean的Id传递给setBeanName()方法 如果Bean实现了BeanFactoryAware接口的话，Spring将调用setBeanFactory()方法，将BeanFactory容器实例传入 如果Bean实现了ApplicationContextAware接口的话，Spring将调用Bean的setApplicationContext()方法，将bean所在应用上下文引用传入进来。 如果Bean实现了BeanPostProcessor接口，Spring就将调用他们的postProcessBeforeInitialization()方法。 如果bean有被@PostConstruct注解的方法，会执行该方法；如果Bean 实现了InitializingBean接口，Spring将调用他们的afterPropertiesSet()方法。类似的，如果bean使用init-method声明了初始化方法，该方法也会被调用 如果Bean 实现了BeanPostProcessor接口，Spring就将调用他们的postProcessAfterInitialization()方法。 此时，Bean已经准备就绪，可以被应用程序使用了。他们将一直驻留在应用上下文中，直到应用上下文被销毁。 如果bean有被@PreDestroy注解的方法，执行该方法；如果bean实现了DisposableBean接口，Spring将调用它的destory()接口方法，同样，如果bean使用了destory-method 声明销毁方法，该方法也会被调用。 https://zhuanlan.zhihu.com/p/158468104 https://blog.csdn.net/qq_20021569/article/details/109178816]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【分布式事务】CAP BASE基本理论及分布式事务解决方案]]></title>
    <url>%2F2020%2F04%2F20%2F%E4%B8%AD%E9%97%B4%E4%BB%B6%2FCAP%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[多个服务多个库，保持在一个事务中CAP 一致性(Consistency) ： 客户端知道一系列的操作都会同时发生(生效)，所有数据备份，同一时刻有同样的值 可用性(Availability) ： 每个操作都必须以可预期的响应结束，一台故障，其他是否可用 分区容错性(Partition tolerance) ： 即使出现某个分区无法可用，区间通信失败，但是访问其他分区依然可以完成 具体地讲在分布式系统中，在任何数据库设计中，一个Web应用至多只能同时支持上面的两个属性。显然，任何横向扩展策略都要依赖于数据分区。因此，设计人员必须在一致性与可用性之间做出选择。 zookeeper CP 需要强一致性 rocket mq Redis AP XA 是一个(2PC)两阶段提交协议，该协议分为以下两个阶段： 第一阶段：事务协调器要求每个涉及到事务的数据库预提交(precommit)此操作，并反映是否可以提交. 第二阶段：事务协调器要求每个数据库提交数据。 其中，如果有任何一个数据库否决此次提交，那么所有数据库都会被要求回滚它们在此事务中的那部分信息。这样做的缺陷是什么呢? 咋看之下我们可以在数据库分区之间获得一致性。 如果CAP 定理是对的，那么它一定会影响到可用性。 如果说系统的可用性代表的是执行某项操作相关所有组件的可用性的和。那么在两阶段提交的过程中，可用性就代表了涉及到的每一个数据库中可用性的和。我们假设两阶段提交的过程中每一个数据库都具有99.9%的可用性，那么如果两阶段提交涉及到两个数据库，这个结果就是99.8%。根据系统可用性计算公式，假设每个月43200分钟，99.9%的可用性就是43157分钟, 99.8%的可用性就是43114分钟，相当于每个月的宕机时间增加了43分钟。 BASE理论 在分布式系统中，我们往往追求的是可用性，它的重要程序比一致性要高，那么如何实现高可用性呢？ 前人已经给我们提出来了另外一个理论，就是BASE理论，它是用来对CAP定理进行进一步扩充的。BASE理论指的是： Basically Available（基本可用） Soft state（软状态） Eventually consistent（最终一致性） 理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency） 刚性任务：强一致性，遵循ACID 柔性事务：最寻BASE理论，最终一致性 分布式事务解决方式：2PC模式，3PC1：先对数据库进行预提交的操作，查询是否可以提交， 2：如果可以提交，就提交数据 如果有任何一个数据库不可以提交，那么所有的数据库都会回滚 TCC事务补偿Try，与准备数据，准备好了进入下一阶段 Confirm，确定是否可以提交 Cancel，如果有任何一个失败，就全部失败 优点 用完就释放，不占用资源 数据最终一致性 最大努力通知方案不保证数据一定能够通知成功，但会提供可查询接口进行核对，结合MQ进行实现 可靠消息，最终一致性业务处理服务在事务提交之前，向实时消息服务请求发送消息，实时消息服务只记录消息，而不真正的发送，业务处理服务在业务事务提交之后，向实时消息服务确认发送，只有得到消息确认发送指令后，实时消息服务才真正发送 Seata 远程服务假失败 远程服务成功，网络故障没有返回 订单回滚，库存却已经扣减 远程服务执行完成，后面出现问题，已执行的远程请求不能够回滚 两阶段提交性能问题：所有参与者在事务提交阶段处于同步阻塞状态，占用链接资源，改进：将提交前和提交后的数据都记录下来，如果需要回滚根据日志回滚 可靠性问题：如果协调者存在单点故障，提供者一直会处于锁定状态，改进：搭建协调者集群 数据一致性问题：阶段2中，如果协调者和参与者都挂掉，补偿机制脚本扫描数据是否正确 消息队列实现分布式事务执行业务，插入事件表，返回给用户已完成 定时任务读取事件表，发送到消息队列，更改事件表状态为已发送 消费消息，读取事件表，操作业务逻辑，更改事件表状态为已处理 响应速度快，最终一致性]]></content>
  </entry>
  <entry>
    <title><![CDATA[【消息队列】消息队列的应用场景和问题]]></title>
    <url>%2F2020%2F03%2F21%2F%E4%B8%AD%E9%97%B4%E4%BB%B6%2Frabbitmq1%2F</url>
    <content type="text"><![CDATA[主要的应用场景业务解耦 A将消息写入消息队列，其他需要的系统直接去消息队列中取，后续扩展方便异步处理 将消息写入消息队列，非必要的业务逻辑以异步方式进行运行流量削峰 当并发量大的时，先将消息存入消息队列，系统按照数据库能处理的并发量从消息队列取消息 消息重复消费消费者在消费消息之后，会发送一个确认给消息队列，消息队列将该消息删除重复消费主要是因为网络传输问题，使确认信息未返回给消息队列，导致消息重复发送解决方法 消息做一个唯一主键，重复消费时，主键冲突，数据库chauffeur失败 做redis的set操作，set操作为幂等操作 用第三方做消息记录，如redis，给消息分配一个全局id，只要消费过该消息，写入redis。在消费前查询redis里面有没有消费记录 消息的可靠性传输丢数据问题，主要分为生产者丢数据，消息队列丢数据，消费者丢数据 生产者丢数据rabbitMQ使用transaction和confirm模式transaction机制，发送消息前开启事务，如果过程出错，回滚；成功提交 吞吐量下降confirm机制，当消息发送给消息队列之后，消息队列发送ack给生产者，若没有处理则发送nack 消息队列丢数据解决方法，开启持久化配置+confirm机制，当消息持久化磁盘之后给生产者发送一个ack信号。如果消息持久化之前，消息队列出问题，生产者自动重发消息开启方法：queue的持久化 durable设置为true，发送消息时将deliveryMode=2 消费者丢数据产生原因：消费者采用了自动确认消息模式，消费者会自动确认收到的消息，消息队列立即将消息删除，而消费者又传异常没处理该消息，产生消息丢失解决方法：手动确认消息，在处理消息之后发送确认消息的顺序性对需要保证顺序执行的消息，放到同一个消息队列，只使用一个消费者对这个队列进行消费]]></content>
  </entry>
  <entry>
    <title><![CDATA[【MySQL】MySQL事务和MVCC机制]]></title>
    <url>%2F2020%2F03%2F05%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMVCC%2F</url>
    <content type="text"><![CDATA[读不加锁，读写不冲突，通过事务的可见性来保证事务能看到自己应该看到的数据版本为了高并发数据库系统中,保证事务与事务之间隔离性和数据一致性,mysql innodb引擎默认是RR的隔离级别,在mysql中通过MVCC快照读和next-key(当前读)两种模式解决幻读问题. 高并发事务 脏读 不可重复读 幻读 更新丢失 MVCC 只工作在read committed and repeatable read 两个隔离级别 undolog多版本链和read view RC隔离级别，每次执行select都生成一个read view RR隔离级别，第一次执行select时生成一个read view，同一个事务后面的select语句复用第一个read view Read uncommitted 总是读取最新的数据行，而不是符合当前事务版本的数据行 而serializable 则会对所有读取的行都加锁 InnoDB 的MVCC是通过每行记录后面保存三个隐藏的列来实现 6字节的事务ID DB_TRX_ID字段，用来表示最近一次对本行记录做修改的事务id 7字节的回滚指针DB_ROLL_PTR字段：用来写入回滚段的undo log record 6字节的DB_ROW_ID字段，一个随着新行插入而单调递增的ID，当由INNODB自动产生聚集索引时，聚集索引会包括这个行ID的值。如果有自己的主键或者合适的唯一索引，那么聚集索引中就不会包含DB_ROW_ID MVCC 特点 每行数据都存在一个版本，每次数据更新时都更新该版本号 修改时copy 出当前版本，然后随意修改，各个事务之间无干扰 保存时比较版本号，如果成功commit， 覆盖原纪录，失败则rollback INNODB 实现的MVCC 的方式， 事务以排他锁的方式修改原始数据 把修改前的数据存放在undolog， 通过回滚指针与主数据关联 修改成功啥都不做，失败则恢复undo log中的数据 MVCC + 悲观锁：MVCC解决读写冲突，悲观锁解决写写冲突 MVCC + 乐观锁：MVCC解决读写冲突，乐观锁解决写写冲突 什么是MVCC全称Multi-Version Concurrency Control，即多版本并发控制，主要是为了提高数据库的并发性能。以下文章都是围绕InnoDB引擎来讲，因为myIsam不支持事务。 同一行数据平时发生读写请求时，会上锁阻塞住。但mvcc用更好的方式去处理读—写请求，做到在发生读—写请求冲突时不用加锁。 这个读是指的快照读，而不是当前读，当前读是一种加锁操作，是悲观锁。 那它到底是怎么做到读—写不用加锁的，快照读和当前读又是什么鬼，跟着你们的贴心老哥，继续往下看。 当前读、快照读都是什么鬼什么是MySQL InnoDB下的当前读和快照读？ 当前读它读取的数据库记录，都是当前最新的版本，会对当前读取的数据进行加锁，防止其他事务修改数据。是悲观锁的一种操作。 如下操作都是当前读： select lock in share mode (共享锁) select for update (排他锁) update (排他锁) insert (排他锁) delete (排他锁) 串行化事务隔离级别 快照读快照读的实现是基于多版本并发控制，即MVCC，既然是多版本，那么快照读读到的数据不一定是当前最新的数据，有可能是之前历史版本的数据。 如下操作是快照读： 不加锁的select操作（注：事务级别不是串行化）快照读与mvcc的关系MVCCC是“维持一个数据的多个版本，使读写操作没有冲突”的一个抽象概念。 这个概念需要具体功能去实现，这个具体实现就是快照读。（具体实现下面讲） 听完贴心老哥的讲解，是不是瞬间茅厕顿开。 数据库并发场景读-读：不存在任何问题，也不需要并发控制 读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读 写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失 MVCC解决并发哪些问题？mvcc用来解决读—写冲突的无锁并发控制，就是为事务分配单向增长的时间戳。为每个数据修改保存一个版本，版本与事务时间戳相关联。 读操作只读取该事务开始前的数据库快照。 解决问题如下： 并发读-写时：可以做到读操作不阻塞写操作，同时写操作也不会阻塞读操作。 解决脏读、幻读、不可重复读等事务隔离问题，但不能解决上面的写-写 更新丢失问题。 因此有了下面提高并发性能的组合拳： MVCC + 悲观锁：MVCC解决读写冲突，悲观锁解决写写冲突 MVCC + 乐观锁：MVCC解决读写冲突，乐观锁解决写写冲突 MVCC的实现原理它的实现原理主要是版本链，undo日志 ，Read View 来实现的 版本链我们数据库中的每行数据，除了我们肉眼看见的数据，还有几个隐藏字段，得开天眼才能看到。分别是db_trx_id、db_roll_pointer、db_row_id。 db_trx_id 6byte，最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务ID。 db_roll_pointer（版本链关键） 7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里） db_row_id 6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以db_row_id产生一个聚簇索引。 实际还有一个删除flag隐藏字段, 记录被更新或删除并不代表真的删除，而是删除flag变了 如上图，db_row_id是数据库默认为该行记录生成的唯一隐式主键，db_trx_id是当前操作该记录的事务ID，而db_roll_pointer是一个回滚指针，用于配合undo日志，指向上一个旧版本。 每次对数据库记录进行改动，都会记录一条undo日志，每条undo日志也都有一个roll_pointer属性（INSERT操作对应的undo日志没有该属性，因为该记录并没有更早的版本），可以将这些undo日志都连起来，串成一个链表，所以现在的情况就像下图一样： 对该记录每次更新后，都会将旧值放到一条undo日志中，就算是该记录的一个旧版本，随着更新次数的增多，所有的版本都会被roll_pointer属性连接成一个链表，我们把这个链表称之为版本链，版本链的头节点就是当前记录最新的值。另外，每个版本中还包含生成该版本时对应的事务id，这个信息很重要，在根据ReadView判断版本可见性的时候会用到。 undo日志Undo log 主要用于记录数据被修改之前的日志，在表信息修改之前先会把数据拷贝到undo log里。 当事务进行回滚时可以通过undo log 里的日志进行数据还原。 Undo log 的用途 保证事务进行rollback时的原子性和一致性，当事务进行回滚的时候可以用undo log的数据进行恢复。 用于MVCC快照读的数据，在MVCC多版本控制中，通过读取undo log的历史版本数据可以实现不同事务版本号都拥有自己独立的快照数据版本。 undo log主要分为两种： insert undo log 代表事务在insert新记录时产生的undo log , 只在事务回滚时需要，并且在事务提交后可以被立即丢弃 update undo log（主要） 事务在进行update或delete时产生的undo log ; 不仅在事务回滚时需要，在快照读时也需要； 所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除 Read View(读视图)事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照。 记录并维护系统当前活跃事务的ID(没有commit，当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以越新的事务，ID值越大)，是系统中当前不应该被本事务看到的其他事务id列表。 Read View主要是用来做可见性判断的, 即当我们某个事务执行快照读的时候，对该记录创建一个Read View读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的undo log里面的某个版本的数据。 Read View几个属性 trx_ids: 当前系统活跃(未提交)事务版本号集合。 min_limit_id: 创建当前read view 时“当前系统最大事务版本号+1”。 max_limit_id: 创建当前read view 时“系统正处于活跃事务最小版本号” creator_trx_id: 创建当前read view的事务版本号； Read View可见性判断条件 db_trx_id &lt; max_limit_id || db_trx_id == creator_trx_id（显示） 如果数据事务ID小于read view中的最小活跃事务ID，则可以肯定该数据是在当前事务启之前就已经存在了的,所以可以显示。 或者数据的事务ID等于creator_trx_id ，那么说明这个数据就是当前事务自己生成的，自己生成的数据自己当然能看见，所以这种情况下此数据也是可以显示的。 db_trx_id &gt;= min_limit_id（不显示） 如果数据事务ID大于read view 中的当前系统的最大事务ID，则说明该数据是在当前read view 创建之后才产生的，所以数据不显示。如果小于则进入下一个判断 db_trx_id是否在活跃事务（trx_ids）中 不存在：则说明read view产生的时候事务已经commit了，这种情况数据则可以显示。 已存在：则代表我Read View生成时刻，你这个事务还在活跃，还没有Commit，你修改的数据，我当前事务也是看不见的。 MVCC和事务隔离级别上面所讲的Read View用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。 RR、RC生成时机RC隔离级别下，是每个快照读都会生成并获取最新的Read View； 而在RR隔离级别下，则是同一个事务中的第一个快照读才会创建Read View, 之后的快照读获取的都是同一个Read View，之后的查询就不会重复生成了，所以一个事务的查询结果每次都是一样的。 解决幻读问题 快照读：通过MVCC来进行控制的，不用加锁。按照MVCC中规定的“语法”进行增删改查等操作，以避免幻读。 当前读：通过next-key锁（行锁+gap锁）来解决问题的。 RC、RR级别下的InnoDB快照读区别在RR级别下的某个事务的对某条记录的第一次快照读会创建一个快照及Read View， 将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，还是使用的是同一个Read View，所以只要当前事务在其他事务提交更新之前使用过快照读，那么之后的快照读使用的都是同一个Read View，所以对之后的修改不可见； 即RR级别下，快照读生成Read View时，Read View会记录此时所有其他活动事务的快照，这些事务的修改对于当前事务都是不可见的。而早于Read View创建的事务所做的修改均是可见 而在RC级别下的，事务中，每次快照读都会新生成一个快照和Read View, 这就是我们在RC级别下的事务中可以看到别的事务提交的更新的原因 总结从以上的描述中我们可以看出来，所谓的MVCC指的就是在使用READ COMMITTD、REPEATABLE READ这两种隔离级别的事务在执行普通的SEELCT操作时访问记录的版本链的过程，这样子可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【K8s】搭建k8s 遇到的问题 failed to pull image k8s.gcr.io/kube-apiserver:v1.19.3:output:Error response from daemon]]></title>
    <url>%2F2020%2F01%2F02%2FK8s%2FK8sPullImageBug%2F</url>
    <content type="text"><![CDATA[无法使用下载k8s镜像的解决办法[ERROR ImagePull]: failed to pull image k8s.gcr.io/kube-apiserver:v1.19.3: output: Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers), error: exit status 1 [ERROR ImagePull]: failed to pull image k8s.gcr.io/kube-controller-manager:v1.19.3: output: Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers), error: exit status 1 [ERROR ImagePull]: failed to pull image k8s.gcr.io/kube-scheduler:v1.19.3: output: Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers), error: exit status 1 根据缺失的image创建如下的shell 脚本 pull_image.sh ，并运行sh pull_image.sh 1234567891011121314images=( kube-apiserver:v1.19.3 kube-controller-manager:v1.19.3 kube-scheduler:v1.19.3 kube-proxy:v1.19.3 pause:3.2 etcd:3.4.13-0 coredns:1.7.0)for imageName in $&#123;images[@]&#125; ; do docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$&#123;imageName&#125; docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$&#123;imageName&#125; k8s.gcr.io/$&#123;imageName&#125; docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$&#123;imageName&#125;done]]></content>
      <categories>
        <category>K8s</category>
      </categories>
      <tags>
        <tag>K8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker的基本使用]]></title>
    <url>%2F2019%2F12%2F26%2FDocker%2Fdocker-use%2F</url>
    <content type="text"><![CDATA[Docker使用不建议使用windows系统进行docker使用，建议使用linux首先安装好linux(版本不要太低)，我用的centos(minimal)和ubuntu 主要是网络问题 一定要记得把自己电脑的vm net service服务开启 安装好之后使用Xshell进行连接，ubuntu要看下ssh是否可用 1234ps -e |grep ssh //查看ssh服务是否有//如果没有安装apt-get install sshservice ssh start ubuntu root账户不能直连的问题 修改/etc/ssh/sshd_config 然后 /etc/init.d/ssh restart 启动ssh 服务 OK，现在开始安装docker了 yum install docker docker 默认镜像pull的很慢 我使用了阿里云的镜像加速 需要去阿里云找镜像加速器 接下来安装软件 docker search 查看安装软件的源 docker pull mysql 默认为最新的 docker pull mysql:5.7指定版本 systemctl daemon-reload systemctl start docker docker start $(docker ps -a -q) 查看latest镜像的具体版本 docker image inspect (docker image名称):latest|grep -i version 为运行中的容器添加映射端口 1`iptables -t nat -A DOCKER -p tcp --dport 8001 -j DNAT --to-destination 172.17.0.19:800012` 提交一个运行中的容器为镜像，docker commit -m ’addimages‘ mycentos jcy/mycentos:v1 运行镜像并添加端口docker run -d -p 8000:80 jcy/mycentos:v1 /bin/bash 运行容器 docker run -d -i -t centos:7 /bin/bash 进入容器 docker exec -it logstash /bin/bash docker attach containerId 如果进入后使用exit 会将容器关闭 12345678910[root@localhost home]# docker run -itd --name=centos7_base centos:7 /bin/bash8aebcca487a8e71ec8a5693bb2160170f33e091f9df2c8053937a6821ef50c51[root@localhost home]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8aebcca487a8 centos:7 "/bin/bash" 3 seconds ago Up 3 seconds centos7_based6d8c141590a logstash:latest "/docker-entrypoin..." 15 hours ago Up 15 hours 0.0.0.0:4560-&gt;4560/tcp logstash60839b634981 kibana:latest "/docker-entrypoin..." 15 hours ago Up 15 hours 0.0.0.0:5601-&gt;5601/tcp kibanae0791cc7e67c elasticsearch:latest "/docker-entrypoin..." 15 hours ago Up 15 hours 0.0.0.0:9200-&gt;9200/tcp, 0.0.0.0:9300-&gt;9300/tcp elasticsearch43d1110fe66e zookeeper "/docker-entrypoin..." 13 months ago Up 16 hours 2888/tcp, 3888/tcp, 0.0.0.0:2181-&gt;2181/tcp, 8080/tcp myzk1[root@localhost home]# docker exec -it centos7_base /bin/bash gem 替换源 gem sources –add https://gems.ruby-china.com/ –remove https://rubygems.org/ https://blog.csdn.net/ke369093457/article/details/89678402]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis Invalid bound statement (not found)]]></title>
    <url>%2F2019%2F12%2F20%2FSpring%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2Fxml%2F</url>
    <content type="text"><![CDATA[已经在yml配置过了对应的location,但是还是出现Invalid bound statement not found问题：在resources下默认以com.msy.mall.dao建出来的默认是文件夹(名字为com.msy.mall.dao)，编译完成之后是会创建一个com.msy.mall.dao的文件夹在建folder时以com/msy/mall/dao 建出来的才是包，编译之后xml才会在对应的dao]]></content>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】JDK1.8新特性]]></title>
    <url>%2F2019%2F10%2F27%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FJava1.8%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[JDK1.8新特性 接口可以有默认方法和静态方法默认方法，可以往现存接口中添加新的方法，不强制那些实现了该接口的类也同时实现这个方法，不改变原有的继承体系，改进接口如java.util.Collection 接口添加新方法，如 stream() 、parallelStream() 、 forEach() 和 removeIf() 静态方法，已经实现的方法，把常用的工具方法写在接口上 当一个类实现两个接口有同名函数 如果方法具有相同的请求参数和返回值，则视为一个方法如果方法有不同的请求参数，就视为两个方法如果方法有相同的请求参数，不同的返回值，则编译出错 lambda表达式不需要匿名对象，直接使用lambda实现匿名表达式Collections.sort(arr,(a,b)-&gt;b.compareTo(a));不需要写参数类型，可以自动推断 函数式接口指仅包含一个抽象方法的接口，每一个类型的lambda表达式都对应一个抽象方法接口，每一个该类型的lambda表达式就会匹配这个抽象方法。 Optional接口防止空指针异常的辅助类型，Optional被定义为一个容器，可为null或者不是null可作为返回类型，如果类型实例有值就返回值，没有值则使用替代行为不是Serializable，不适合作为类的字段 Stream接口Stream，Collections里面的只能对List或者Set创建Stream对象类似于迭代器Iterator，单向，不可往复，数据只遍历一次，对集合中的元素进行筛选过滤，排序，修改 新的Date接口LocalDate，LocalTime，LocalDateTime，都是不可变的DateTimeFormatter线程安全的，原来的SimpleDateFormat不是线程安全的 JDK1.8 Stream的使用]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】并发工具类CyclicBarrier、CountDownLatch、Semaphore、Exchanger、Phaser]]></title>
    <url>%2F2019%2F10%2F23%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FJava%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[CyclicBarrier，循环栅栏允许让一组线程进行相互等待await()，直到达到公共屏障点，才会将阻塞的这些线程释放并通过先调用barrierAction，然后让他们一起继续工作，在释放线程之后可以重用。 内部主要使用重入锁ReentrantLock和Condition实现构造方法： 1234567891011public CyclicBarrier(int parties, Runnable barrierAction) &#123;//通过传入Runnable，当达到屏障时先执行barrierAction if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction;&#125;public CyclicBarrier(int parties) &#123; this(parties, null);&#125; 主要方法：//等到所有的线程都到达指定的临界点await() throws InterruptedException, BrokenBarrierException //与上面的await方法功能基本一致，只不过这里有超时限制，阻塞等待直至到达超时时间为止await(long timeout, TimeUnit unit) throws InterruptedException,BrokenBarrierException, TimeoutException //获取当前有多少个线程阻塞等待在临界点上int getNumberWaiting() //用于查询阻塞等待的线程是否被中断boolean isBroken() //将屏障重置为初始状态。如果当前有线程正在临界点等待的话，将抛出BrokenBarrierException。void reset() 当出现异常时使用breakBarrier()终止所有线程 CountDownLatch，倒计时器让一个或多个线程等待其他若干个线程执行完，当计数器为0时，所有等待的线程才可以继续执行，无法被重置 通过共享锁Sync实现，需要传入一个int参数，指定要多少线程执行完，才让等待的线程执行 构造函数1234public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException("count &lt; 0"); this.sync = new Sync(count);&#125; 内部方法： await() throws InterruptedException：调用该方法的线程等到构造方法传入的N减到0的时候，才能继续往下执行； await(long timeout, TimeUnit unit)：与上面的await方法功能一致，只不过这里有了时间限制，调用该方法的线程等到指定的timeout时间后，不管N是否减至为0，都会继续往下执行； countDown()：使CountDownLatch初始值N减1； long getCount()：获取当前CountDownLatch维护的值； Semaphore，信号量限制可以访问某些资源的线程数目默认为非公平锁，可通过构造函数指定公平性，当semaphore=1，可以当做是一个互斥锁使用=1，其他线程可以获取=0，排他，其他线程阻塞构造函数1234567public Semaphore(int permits) &#123; sync = new NonfairSync(permits);&#125;public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits);&#125; 内部主要方法：acquire(); 获取许可，信号量-1；当信号量&gt;0，可以获取，若信号量=0，阻塞release(); 释放许可，信号量+1 Exchanger，交换器允许在并发任务之间交换数据。通过定义两个线程之间的同步点，当两个线程都达到同步点时，交换数据在Exchanger中，如果一个线程已经到达了exchanger节点时，对于它的伙伴节点的情况有三种： 如果它的伙伴节点在该线程到达之前已经调用了exchanger方法，则它会唤醒它的伙伴然后进行数据交换，得到各自数据返回。 如果它的伙伴节点还没有到达交换点，则该线程将会被挂起，等待它的伙伴节点到达被唤醒，完成数据交换。 如果当前线程被中断了则抛出异常，或者等待超时了，则抛出超时异常。 Phaser，阶段器进行并发阶段任务运行，一个任务分为多个阶段，每个阶段完成之后才能进行下一阶段的运行phase就是阶段，初值为0，当所有的线程执行完当前阶段任务已结束，进入到下一阶段任务，phase的值自动加1。parties就是线程， parties=4就意味着Phaser对象当前管理着4个线程。 主要方法：register()，动态的添加一个或多个线程int arriveAndAwaitAdvance()，相当于await()方法，记录到达线程数，阻塞等待其他线程到达同步点后再继续执行。arriveAndDeregister()，动态的撤销线程的注册，该线程已结束，不再参与后续的阶段boolean onAdvance(int phase,int register)，当每一阶段结束调用该方法， 默认是所有线程都撤销注册为止，return true，阶段停止，可重写该方法设置自定义阶段响应。 123protected boolean onAdvance(int phase, int registeredParties) &#123; return registeredParties == 0;&#125; 参考资料Java并发编程艺术 方腾飞Java并发编程实战 Brian Goetz / Tim Peierls / Joshua Bloch / Joseph Bowbeer / David Holmes / Doug Lea 大白话说java并发工具类-CountDownLatch，CyclicBarrier死磕Java并发Java并发——Phaser “阶段器”]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Spring】Spring中的事务的属性、隔离级别、传播机制]]></title>
    <url>%2F2019%2F10%2F22%2FSpring%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2Fspring-transactional%2F</url>
    <content type="text"><![CDATA[Spring的事务管理分为编程式事务和声明式事务两种。编程式事务：通过编码方式TransactionTemplate或者直接使用底层的PlatformTransactionManager实现事务控制声明式事务：基于AOP，通过XML或注解@Transactional实现，将业务逻辑和事务处理解耦 Spring的默认事务处理只能进行回滚运行时、未检查的异常或者Error并且默认只能用到public方法(AOP的JDK动态代理问题，下文解释) @Transactional注解属性说明 属性名 说明 name 当在配置文件中有多个 TransactionManager , 可以用该属性指定选择哪个事务管理器。 propagation 事务的传播行为，默认值为 REQUIRED。 isolation 事务的隔离度，默认值采用 DEFAULT。 timeout 事务的超时时间，默认值为-1。如果超过该时间限制但事务还没有完成，则自动回滚事务。 read-only 指定事务是否为只读事务，默认值为 false；为了忽略那些不需要事务的方法，比如读取数据，可以设置 read-only 为 true。 rollback-for 用于指定能够触发事务回滚的异常类型，如果有多个异常类型需要指定，各类型之间可以通过逗号分隔。 no-rollback- for 抛出 no-rollback-for 指定的异常类型，不回滚事务。 propagation属性指定事务的传播方式，默认为REQUIRED 名称 解释 Propagation.REQUIRED 如果当前存在事务，则加入该事务，如果当前不存在事务，则创建一个新的事务。 Propagation.NESTED 和 Propagation.REQUIRED 效果一样。 Propagation.MANDATORY 如果当前存在事务，则加入该事务；如果当前不存在事务，则抛出异常。 Propagation.REQUIRES_NEW 重新创建一个新的事务，如果当前存在事务，暂停当前的事务。 Propagation.NOT_SUPPORTED 以非事务的方式运行，如果当前存在事务，暂停当前的事务。 Propagation.SUPPORTS 如果当前存在事务，则加入该事务；如果当前不存在事务，则以非事务的方式继续运行。 Propagation.NEVER 以非事务的方式运行，如果当前存在事务，则抛出异常。 isolation属性隔离级别是指若干个并发的事务之间的隔离程度。TransactionDefinition 接口中定义了五个表示隔离级别的常量： 值 解释 TransactionDefinition.ISOLATION_DEFAULT 默认值，表示使用底层数据库的默认隔离级别。对大部分数据库而言，通常这值就是ISOLATION_READ_COMMITTED。 TransactionDefinition.ISOLATION_READ_COMMITTED 该隔离级别表示一个事务只能读取另一个事务已经提交的数据。该级别可以防止脏读，这也是大多数情况下的推荐值。 TransactionDefinition.ISOLATION_READ_UNCOMMITTED 该隔离级别表示一个事务可以读取另一个事务修改但还没有提交的数据。该级别不能防止脏读和不可重复读，因此很少使用该隔离级别。 TransactionDefinition.ISOLATION_REPEATABLE_READ 该隔离级别表示一个事务在整个过程中可以多次重复执行某个查询，并且每次返回的记录都相同。即使在多次查询之间有新增的数据满足该查询，这些新增的记录也会被忽略。该级别可以防止脏读和不可重复读。 TransactionDefinition.ISOLATION_SERIALIZABLE 串行化，所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。 rollbackfor属性默认情况下，如果在事务中抛出了未检查异常（继承自 RuntimeException 的异常）或者 Error，则 Spring 将回滚事务；除此之外，Spring 不会回滚事务。 如果在事务中抛出其他类型的异常，并期望 Spring 能够回滚事务，可以指定 rollbackFor。例：@Transactional(propagation= Propagation.REQUIRED,rollbackFor= MyException.class) 通过分析 Spring 源码可以知道，若在目标方法中抛出的异常是 rollbackFor 指定的异常的子类，事务同样会回滚。 Spring中事务的实现机制当应用系统调用声明了 @Transactional 的目标方法时，Spring Framework 默认使用 AOP 代理，在代码运行时生成一个代理对象，根据 @Transactional 的属性配置信息，这个代理对象决定该声明 @Transactional 的目标方法是否由拦截器 TransactionInterceptor 来使用拦截，在 TransactionInterceptor 拦截时，会在目标方法开始执行之前创建并加入事务，并执行目标方法的逻辑, 最后根据执行情况是否出现异常，利用抽象事务管理器 AbstractPlatformTransactionManager 操作数据源 DataSource 提交或回滚事务。 Spring AOP 代理有 CglibAopProxy 和 JdkDynamicAopProxy 两种，以 CglibAopProxy 为例，对于 CglibAopProxy，需要调用其内部类的 DynamicAdvisedInterceptor 的 intercept 方法。对于 JdkDynamicAopProxy，需要调用其 invoke 方法。 事务管理的框架是由抽象事务管理器 AbstractPlatformTransactionManager 来提供的，而具体的底层事务处理实现，由 PlatformTransactionManager 的具体实现类来实现，如事务管理器 DataSourceTransactionManager。不同的事务管理器管理不同的数据资源 DataSource，比如 DataSourceTransactionManager 管理 JDBC 的 Connection。 @Transational 为什么只能使public方法有效在使用注解@Transactional时，Spring默认使用AOP代理，在代码运行时生成代理对象，通过TransactionInterceptor 在目标方法执行前后进行拦截之前，DynamicAdvisedInterceptor（CglibAopProxy 的内部类）的 intercept 方法或 JdkDynamicAopProxy 的 invoke 方法会间接调用 AbstractFallbackTransactionAttributeSource（Spring 通过这个类获取@Transactional 注解的事务属性配置属性信息）的 computeTransactionAttribute 方法，这个方法会检查方法是否为public，若不是则不会获取@Transactional的属性配置信息，造成TransactionInterceptor不会去拦截该目标方法进行事务管理。 12345protected TransactionAttribute computeTransactionAttribute(Method method,Class&lt;?&gt; targetClass) &#123;// Don't allow no-public methods as required if(allowPublicMethodsOnly()&amp;&amp;!Modifier.isPublic(method.getModifiers())&#123; return null;&#125; Transactional 注解失效的情况 非public方法修饰的方法 原因： 事务是基于AOP动态代理实现的，如果类或者方法的修饰符不是public，@Transactional 注解就不会对Bean或者方法进行代理调用。底层实现会去比较TransactionalAttribute，如果是public 会返回null 在动态代理对象，进行代理调用时，会获取当前需要执行方法适配的AOP逻辑（DynamicAdvisedInceptor） static 修饰的方法也会导致事务失效 原因： 静态方法是类级别的，调用需要知道类信息，而类信息在编译器就已经知道了，并不支持在运行期的动态绑定。 一个没有事务的方法调用一个有事务的方法，事务会被忽略 原因：在类内部调用类内部的事务方法时并不是通过代理对象来调用的，而是通过this对象来调用方法，所以就绕过了代理对象导致失效 以上两个问题可使用AspectJ代替SpringAOP代理解决。 事务方法内部捕获了异常（try catch）， 没有抛出新的异常，事务失效 原因：因为事务想要回滚，是在事务invokeWithinTranaction在这里会抛出异常，如果加事务的方法有了try catch，那么异常中途就会被捕捉掉，所以事务失效。，此时应该在try catch 中自己提交或者回滚 异常类型错误 默认回滚的是：RuntimeException非检查异常，如果你想触发其他异常的回滚，需要在注解上配置一下，如： 1@Transactional(rollbackFor = Exception.class) —- 3 解释：因为当ServiceB中抛出了一个异常以后，ServiceB标识当前事务需要rollback。但是ServiceA中由于你手动的捕获这个异常并进行处理，ServiceA认为当前事务应该正常commit。此时就出现了前后不一致，也就是因为这样，抛出了前面的UnexpectedRollbackException异常。 spring的事务是在调用业务方法之前开始的，业务方法执行完毕之后才执行commit or rollback，事务是否执行取决于是否抛出runtime异常。如果抛出runtime exception 并在你的业务方法中没有catch到的话，事务会回滚。 在业务方法中一般不需要catch异常，如果非要catch一定要抛出throw new RuntimeException()，或者注解中指定抛异常类型@Transactional(rollbackFor=Exception.class)，否则会导致事务失效，数据commit造成数据不一致，所以有些时候try catch反倒会画蛇添足。 参考链接Spring Boot 中使用 @Transactional 注解配置事务管理透彻的掌握 Spring 中@transactional 的使用Spring Framework文档stackoverflow-transactional只能使用在publichttps://www.ibm.com/developerworks/cn/education/opensource/os-cn-spring-trans/index.html]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】解析各种阻塞队列]]></title>
    <url>%2F2019%2F10%2F21%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FJava%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[各种队列的基本操作，内部大都使用ReentrantLock和Condition进行入队出队的阻塞控制 操作 抛出异常 返回特殊值null 阻塞等待 超时返回false 入队 add(E e) offer(E e) put(E e) offer(E e,long timeout ,TimeUnit unit) 出队 remove(obj) poll() take() poll(long timeout ,TimeUnit unit) ArrayBlockingQueue由数组实现的有界阻塞队列大小构造函数确定，不能动态修改大小默认非公平，可设置公平性 LinkedBlockingQueue由链表组成的有界阻塞队列，可从尾部和头部进行插入和删除操作容量可选默认为Integer.MAX_VALUE，可设置大小防止过度膨胀使用putFirst、putLast、pollFirst、pollLast内部又调用linkFirst、linkLast、unlinkFirst、unlinkLast方法进行队列的操作 PriorityBlockingQueue由二叉堆(小顶堆)实现的可设置优先级的无界阻塞队列，但不可保证同优先级元素的顺序默认升序，可设置comparator默认容量11，最大容量Integer.MAX_VALUE扩容方式： int newCap = oldCap + ((oldCap &lt; 64) ? (oldCap + 2) : (oldCap &gt;&gt; 1)); // 容量小于64，则每次容量+2，否则变为1.5倍大小 DelayQueue支持延时获取元素的无界阻塞队列内部使用PriorityQueue优先队列，控制过期时间优先级，最先过期的优先级最高在队头通过重入锁，和Condition控制阻塞，通过Thead leader对象来判断当前线程是否被占用主要可使用在：清除过期缓存，超时任务处理 SynchronousQueue不存储元素的BlockingQueue，每个put操作必须等待一个take，否则阻塞可设置公平性，默认非公平，公平模式使用TransferQueue，非公平使用TransferStack适合进行数据的转移 LinkedTransferQueue入队时如果有消费者等待，就立即交出，如果没有就将元素添加到队尾出队时如果队列中有元素就直接取出，如果没有就一直在这个位置等待直到拿到数据或者超时中断，此时tryTransfer()自旋若有新元素就不会进入队列，直接出队被消费者消费，不进行阻塞 参考资料Java并发编程艺术 方腾飞Java并发编程实战 Brian Goetz / Tim Peierls / Joshua Bloch / Joseph Bowbeer / David Holmes / Doug Leajava并发编程笔记–PriorityBlockingQueue实现【死磕Java并发】—–J.U.C之阻塞队列Java 优先队列 PriorityQueue PriorityBlockingQueue 源码分析]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】Reflect反射]]></title>
    <url>%2F2019%2F10%2F19%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FJava-Reflect%2F</url>
    <content type="text"><![CDATA[在JVM运行期，动态加载类或者调用方法，获取属性，事先不需要知道运行的对象是谁，解耦提高代码的灵活度根据类名创建一个实例，不需要直接去new 在运行时获取类的信息，类中字段信息，判断类所属的包构造一个类的对象动态调用方法 当获取私有字段时需要暴力反射：name.setAccessible(true) 缺点：为了接口的通用性，Java的invoke方法是传object和object[]数组的。基本类型参数需要装箱和拆箱，产生大量额外的对象和内存开销，频繁促发GC。编译器难以对动态调用的代码提前做优化，比如方法内联。反射需要按名检索类和方法，有一定的时间开销。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】类加载机制，全盘负责，双亲委派，类初始化过程]]></title>
    <url>%2F2019%2F10%2F15%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FJavaClassLoader%2F</url>
    <content type="text"><![CDATA[类装载工作由ClassLoder和其子类负责。JVM在运行时会产生三个ClassLoader：(BootStrap)根装载器，ExtClassLoader(扩展类装载器)和AppClassLoader，其中根装载器不是ClassLoader的子类，由C++编写，因此在java中看不到他，负责装载JRE的核心类库。 全盘负责委托Java装载类使用“全盘负责委托机制”指ClassLoader装载一个类时，除非显示的使用另一个ClassLoader，否则该类所依赖和引用的类也由这个ClassLoader载入。 双亲委派模型如果一个类加载器收到了类加载的请求，它首先不会自己去加载这个类，而是把这个请求委派给父类加载器去完成，每一层的类加载器都是如此，这样所有的加载请求都会被传送到顶层的启动类加载器中，只有当父加载无法完成加载请求（它的搜索范围中没找到所需的类）时，子加载器才会尝试去加载类。好处：保证任何的类加载器最终得到的是同一个Object对象 双亲委派加载Class详细过程： 源ClassLoader先判断该Class是否已加载，如果已加载，则返回Class对象；如果没有则委托给父类加载器。 父类加载器判断是否加载过该Class，如果已加载，则返回Class对象；如果没有则委托给祖父类加载器。 依此类推，直到始祖类加载器（引用类加载器）。 始祖类加载器判断是否加载过该Class，如果已加载，则返回Class对象；如果没有则尝试从其对应的类路径下寻找class字节码文件并载入。如果载入成功，则返回Class对象；如果载入失败，则委托给始祖类加载器的子类加载器。 始祖类加载器的子类加载器尝试从其对应的类路径下寻找class字节码文件并载入。如果载入成功，则返回Class对象；如果载入失败，则委托给始祖类加载器的孙类加载器。 依此类推，直到源ClassLoader。 源ClassLoader尝试从其对应的类路径下寻找class字节码文件并载入。如果载入成功，则返回Class对象；如果载入失败，源ClassLoader不会再委托其子类加载器，而是抛出异常。 Java类加载过程类装载器把一个类装入Java虚拟机中，要经过三个步骤来完成： ①编译加载（以二进制形式来生成Class对象）②链接（又分为验证、准备和解析） 校验：检查导入类或接口的二进制数据的正确性； 准备：给类的静态变量分配并初始化存储空间，初始化为默认值； 解析：虚拟机将常量池中的符号引用替换成直接引用的过程。符号引用就理解为一个标示，而在直接引用直接指向内存中的地址；③初始化（激活类的静态变量和静态代码块、初始化Java代码） Java类初始化过程 先初始化静态成员，静态代码块，父类空白（构造）代码块，然后调用父类构造器，再初始化父类非静态成员，最后调用自身构造器，自身空白（构造）代码块，自身非静态成员。1.父类静态变量、父类静态代码块 static{ }2.子类静态变量、子类静态代码块 static{ }3.父类字段初始化 ，如private String name =”base”4.父类非静态代码块（空白代码块） {} 5.父类构造方法6.子类字段初始化，如private String name=”sub”;7.子类非静态代码块{}8 子类构造方法 定义自已的类加载器分为两步： 1、继承java.lang.ClassLoader2、重写父类的findClass方法 为什么偏偏只重写findClass方法？ 因为JDK已经在loadClass方法中帮我们实现了ClassLoader搜索类的算法，当在loadClass方法中搜索不到类时，loadClass方法就会调用findClass方法来搜索类，所以我们只需重写该方法即可。如没有特殊的要求，一般不建议重写loadClass搜索类的算法。 如果想保持双亲委派模型，就应该重写findClass(name)方法；如果想破坏双亲委派模型，可以重写loadClass(name)方法。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】深浅拷贝，Object.Clone]]></title>
    <url>%2F2019%2F10%2F15%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2F%E6%B7%B1%E6%B5%85%E6%8B%B7%E8%B4%9D%2F</url>
    <content type="text"><![CDATA[浅拷贝和深拷贝浅拷贝，创建一个新对象，然后将当前对象的非静态字段复制到该对象，如果字段类型是基本数据类型就对字段进行复制，如果字段类型是引用类型则只复制该字段的引用而不复制引用指向的对象修改复制的对象，原对象也会发生改变 深拷贝就是将所有字段的对象复制一份新的，修改复制的对象不会改变原对象 Object.clone()源码必须继承object，Java中所有类都默认继承Object，重写clone()，将clone的protected改为public，默认返回Object，必须要进行强制类型转换才能得到需要的类型，并且是浅拷贝 实现深度拷贝方法1 将引用对象也实现Cloneable接口，方法2 实现串行化接口，将对象的拷贝先写入流中，然后再读出，实现对象的重建]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】volatile关键字解析]]></title>
    <url>%2F2019%2F10%2F15%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2Fvolatile%2F</url>
    <content type="text"><![CDATA[volatile只能保证多线程中的可见性和有序性，不能保证原子性。volatile关键字是否能保证线程安全？（）答案：不能解析：volatile关键字用在多线程同步中可保证读取的可见性（并发编程中当多个线程访问同一个变量时，一个线程对变量进行了修改，其他线程能够立马看到修改之后的值），1.当某个线程对该变量修改后，会立即将修改后的新值刷回主存，保证主存中永远都是最新的数据2.对该比变量施加了缓存行一致协议。也就是说，当前线程对该变量进行修改后，系统会通知其他线程它们工作缓存中数据已经无效，那么其他线程要再次读取该变量时，就会重新从主存中读取该变量，然后复制一份在它的工作缓存中。JVM只是保证从主内存加载到线程工作内存的值是最新的读取值，而非cache中。 可保证有序性(程序按照代码的先后顺序进行执行)能够禁止指令进行重排序，保证有序性volatile关键字禁止指令重排序有两层意思：1）当程序执行到volatile变量的读操作或者写操作时，在其前面作的操的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。 保证不了原子性问题(一个或多个操作，要么全部执行且不可被打断，要么都不执行)可保证单一操作的原子性，不能保证复合操作的原子性PS . 在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）即这些操作是不可被中断的，要么执行，要么不执行。 i++执行了多部操作,从变量i中读取读取i的值-&gt;值+1 -&gt;将+1后的值写回i中，不能保证原子性和线程安全 在修饰数组时只是修饰指向数组的这个引用，而不是数组的内容，内容修改对其它线程不可见主要的功能是保护变量不被主函数和中断函数反复修改造成读写错误。但多个线程对volatile的写操作，无法保证线程安全。例如假如线程1，线程2 在进行read,load 操作中，发现主内存中count的值都是5，那么都会加载这个最新的值，在线程1堆count进行修改之后，会write到主内存中，主内存中的count变量就会变为6；线程2由于已经进行read,load操作，在进行运算之后，也会更新主内存count的变量值为6；导致两个线程即使用volatile关键字修改之后，还是会存在并发的情况。 参考链接：Java并发编程：volatile关键字解析死磕Java并发-深入理解volatile]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Redis】内存淘汰机制、缓存问题及解决、持久化方案]]></title>
    <url>%2F2019%2F10%2F15%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fredis-study1%2F</url>
    <content type="text"><![CDATA[Redis性能好，对一些结果变化不频繁的结果，存入缓存，加快请求响应高并发进行削峰，减少同一时间对数据库的请求数量，防止数据库崩溃 常用场景 缓存， 计数器， 分布式锁， 排行榜，zset 最新列表， 消息队列 Redis的常用基本数据类型 (一)string内部使用sds实现，简单动态字符串。最常规的set/get操作，value可以是String也可以是数字。一般做一些复杂的计数功能的缓存。(二)hash内部使用zipmap(数据量少时使用)或者dict实现，这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。(三)list内部使用quicklist进行实现，quicklist的每一个节点都是ziplist，双向链表，使用List的数据结构，可以做简单的消息队列的功能。另外还有一个就是，可以利用lrange命令，做基于redis的分页功能，性能极佳，用户体验好。(四)set当set元素少时底层数据使用intset实现，否则使用dict实现。因为set堆放的是一堆不重复值的集合，所以可以做全局去重的功能。为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。(五)sorted set数据量少时使用ziplist，数据量多(数据对z的数目超过128或单个数据的长度超过64)使用dict(基于hash表，使用rehash进行冲突解决)和skiplist进行实现(zset)，sorted set多了一个权重参数score,集合中的元素能够按score进行排列。可以做排行榜应用，取TOP N操作、可以用来做延时任务、可以做范围查找。当zset满足以下两个条件的时候，使用ziplist： 保存的元素少于128个 保存的所有元素大小都小于64字节 其他skiplist，多了一个权重参数score,集合中的元素能够按score进行排列。可以做排行榜应用，取TOP N操作、可以用来做延时任务、可以做范围查找。 延时队列：当前时间戳和延时时间相加，也就是到期时间，存入Redis中，然后不断轮询，拿出score比当前时间戳大的数据，找到到期的，拿到再删除即可 Redis的内部数据结构主要有dict、sds、ziplist、quicklist、skiplist dictdict基于Hash表的算法，使用拉链法解决冲突，在装在椅子超过预定的值时触发重哈希，重哈希使用的是增量式重hash，避免一次性对所有的key进行重hash造成单个请求的响应时间剧烈增加，每次只对一部分key进行重hash。dict里面包括两个哈希表dictint，在重哈希期间，数据从第一个哈希表转移到第二个哈希表。 sds simple dynamic string可以动态扩展，内容可增可修改。二进制安全，可打印任意二进制数据。 ziplist经过编码的双向链表，存储效率高。各个数据项紧挨在一起占用连续的内存空间，不适合修改操作，如果数据发生变动引发realloc，可能会导致内存拷贝。 quicklist双向链表，每一个节点都存储一个ziplist skiplist跳表，与hash表相比有序，hash表适合进行单个值得查找，不适合进行范围查找；平衡树的查找比跳表更加复杂，而且进行插入和删除时可能引发树的调整。 intset整数组成的集合，内存分配与ziplist类似，连续的一整块内存空间，对大整数和小整数(绝对值)使用不同的编码方式，始终保持从小到大的顺序。 robjredis object 根据type表示外部的数据类型(stirng、hash…)，根据字段encoding的不同可表示任意的上述内部数据类型(dict …) Redis的RESP协议规范 均已\r\n结尾 简单字符串 Simple Strings, 以 “+”加号 开头 错误 Errors, 以”-“减号 开头 整数型Integer，以”:”冒号开头 多行字符串，以”$”美元符号开头 数组Arrays，以”*”星号开头 单线程Redis为何这么快 纯内存操作 单线程，避免了频繁的上下文切换，不用考虑各种锁，每秒10w 使用了非阻塞IO多路复用，同一个线程同时处理多个请求 渐进式ReHash 缓存时间戳，不是调用系统时间，对时间进行缓存更新，获得时间是从缓存中取 渐进式rehash，使用两张全局哈希表，hash表2 是hash表1的2倍，将hash表1拷贝到hash表2，每一个客户端请求导致hash冲突只拷贝当前冲突，将一次性的拷贝分摊到了多次请求中 如果一张hash表处理冲突时，可能需要扩容，rehash后可能数据要移动，导致阻塞 Redis的过期策略和内存淘汰机制，及内存不足的处理办法 redis64位内存默认大小无限制，查看info memory/config get maxmemory 比如你redis只能存5G数据，可是你写了10G，那会删5G的数据。怎么删的，这个问题思考过么？还有，你的数据已经设置了过期时间，但是时间到了，内存占用率还是比较高，有思考过原因么?回答:内存不足的处理办法： 增加内存 对内存设置淘汰策略 使用redis集群 redis采用的是定期删除+惰性删除策略。为什么不用定时删除策略?定时删除，用一个定时器来负责监视key，过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key，因此没有采用这一策略.定期删除+惰性删除是如何工作的呢?定期删除，redis默认每隔100ms检查，是否有过期的key，有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms，全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。采用定期删除+惰性删除就没其他问题了么?不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制。在redis.conf中有一行配置maxmemory-policy volatile-lru该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己)1）noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。不推荐2）allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。推荐使用，目前项目在用这种。3）allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。应该也没人用吧，你不删最少使用Key,去随机删。4）allkeys-lfu: 对所有的key，删除最少使用频率的5）volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。这种情况一般是把redis既当缓存，又做持久化存储的时候才用。不推荐6）volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。依然不推荐7）volatile-lfu：对设置了过期的key中，删除最少使用频率的6）volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。不推荐 ps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。 近似lru算法，给每一个key增加一个小字段，最后一次被访问的时间戳，随机采样出几个key，根据时间戳淘汰，使用池化淘汰候选吃提升lru算法的效果 使用缓存的缺点 缓存和数据库双写一致性问题 缓存雪崩问题 缓存穿透问题 缓存并发竞争问题 缓存一致性问题 一致性分为最终一致性（通俗来说就是最后结果相同）和强一致性(每时每刻都是相同的)。强一致性要求的需要加锁。 双写模式，先写数据库改完之后写缓存，数据不一致，第一个写缓存在第二个写缓存之后，缓存设置过期时间，过期之后又能得到新的正确的，最终一致 cache aside 机制失效模式：先更新数据库，再删除缓存，也可能造成暂时不一致 线程a写数据库1，线程b写2，线程c读，b还未写完，c读到数据库为1，更新缓存为1 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。命中：应用程序从cache中取数据，取到后返回。更新：先把数据存到数据库中，成功后，再让缓存失效。 先删缓存再更新数据库。使用延时双删策略解决暂时不一致性，先删缓存再写数据库，休眠1s，再删除缓存先更新db 后删除缓存 Read/Write Through机制，调用方只和缓存交互，读直接读缓存，写先写入缓存，由缓存同步到数据库 缓存雪崩问题 缓存雪崩，即缓存失效时间相同，同一时间大面积的失效，或者redis故障失效（集群解决，hystrix限流），这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。解决方案: 给缓存的失效时间，加上一个随机值，避免集体失效。 使用互斥锁，但是该方案吞吐量明显下降了。 多级缓存。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点 I 从缓存A读数据库，有则直接返回II A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。III 更新线程同时更新缓存A和缓存B。 缓存穿透问题 缓存穿透，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。解决方案: 采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。 提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。适用于大用户集，实时性要求较低的场景，如有几亿的数据集，每隔一段时间会新增用户进去，在更新之前新用户的访问会存在缓存穿透问题。 利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试 缓存击穿问题 对于一些设置了过期时间的key，可能是一个热点数据，在某时高并发访问，此时正好失效，所有数据查询都查数据库 解决方案：加锁，利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试 Redis缓存并发竞争 基于zookeeper实现分布式锁，每个通过zookeeper获取分布式锁，确保同一时间，只有一个实例在操作某个key。当进行写之前，判断当前的value时间戳是否比缓存里面的时间戳新，若是则写，否则，不能使用旧数据覆盖新数据。 redis 的 setnx 实现内置的锁：要设置超时时间，防止抢占到锁的客户端因失败、崩溃或其他原因没有办法释放锁而造成死锁 利用redis自带的incr命令,decr命令 使用乐观锁的方式进行解决，通过watch进行监控，后面的事务有条件执行，如果在watch的exec执行时，watch的key对应的value改变了，事务不进行执行，但是不推荐使用redis的事务机制。因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。 Redis持久化方案 RDB在指定的时间间隔能对你的数据进行快照存储。执行bgsave AOF使用日志记录所有的写操作，在服务器启动时，通过执行这些命令还原数据库。AOF的持久化更加完整，安全，默认每秒钟fsync一次，出现故障时可使用redis-check-aof进行问题修复，并且自己可以对aof文件进行重写RDB可能会丢失数据，但是体积更小，保存某个时间点的所有数据，进行大数据集恢复时速度要快一般两种方式同时使用，在同时使用时，优先使用AOF进行数据集的恢复 AOF 的工作流程，写入命令追加到缓冲区，根据策略对硬盘进行同步，定期对AOF文件进行重写 Canal 更新缓存：mysql 的从服务器，只要更新了DB，Canal更新redis 解决数据异构：不同用户生成不同的表 为什么redis需要把所有数据放到内存中 速度快，存在过期淘汰机制不会出现oom redis 哨兵模式通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机 故障切换（failover）的过程。假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为主观下线。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为客观下线 选举步骤故障节点主观下线故障节点客观下线Sentinel集群选举LeaderSentinel Leader决定新主节点选举过程1、主观下线Sentinel集群的每一个Sentinel节点会定时对redis集群的所有节点发心跳包检测节点是否正常。如果一个节点在down-after-milliseconds时间内没有回复Sentinel节点的心跳包，则该redis节点被该Sentinel节点主观下线。 2、客观下线当节点被一个Sentinel节点记为主观下线时，并不意味着该节点肯定故障了，还需要Sentinel集群的其他Sentinel节点共同判断为主观下线才行。 该Sentinel节点会询问其他Sentinel节点，如果Sentinel集群中超过quorum数量的Sentinel节点认为该redis节点主观下线，则该redis客观下线。 如果客观下线的redis节点是从节点或者是Sentinel节点，则操作到此为止，没有后续的操作了；如果客观下线的redis节点为主节点，则开始故障转移，从从节点中选举一个节点升级为主节点。 3、Sentinel集群选举Leader如果需要从redis集群选举一个节点为主节点，首先需要从Sentinel集群中选举一个Sentinel节点作为Leader。 每一个Sentinel节点都可以成为Leader，当一个Sentinel节点确认redis集群的主节点主观下线后，会请求其他Sentinel节点要求将自己选举为Leader。被请求的Sentinel节点如果没有同意过其他Sentinel节点的选举请求，则同意该请求(选举票数+1)，否则不同意。 如果一个Sentinel节点获得的选举票数达到Leader最低票数(quorum和Sentinel节点数/2+1的最大值)，则该Sentinel节点选举为Leader；否则重新进行选举。 4、Sentinel Leader决定新主节点当Sentinel集群选举出Sentinel Leader后，由Sentinel Leader从redis从节点中选择一个redis节点作为主节点： 过滤故障的节点选择优先级slave-priority最大的从节点作为主节点，如不存在则继续选择复制偏移量（数据写入量的字节，记录写了多少数据。主服务器会把偏移量同步给从服务器，当主从的偏移量一致，则数据是完全同步）最大的从节点作为主节点，如不存在则继续选择runid（redis每次启动的时候生成随机的runid作为redis的标识）最小的从节点作为主节点 为什么Sentinel集群至少3节点一个Sentinel节选举成为Leader的最低票数为quorum和Sentinel节点数/2+1的最大值，如果Sentinel集群只有2个Sentinel节点，则 Sentinel节点数/2 + 1= 2/2 + 1即Leader最低票数至少为2，当该Sentinel集群中由一个Sentinel节点故障后，仅剩的一个Sentinel节点是永远无法成为Leader。 也可以由此公式可以推导出，Sentinel集群允许1个Sentinel节点故障则需要3个节点的集群；允许2个节点故障则需要5个节点集群。 Redis主从复制全量同步 Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： 从服务器连接主服务器，发送SYNC命令； 主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令； 增量同步 Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。 Redis主从同步策略 主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。 主从复制是从节点异步复制备份，可能会存在写操作数据丢失 Redis 事务 MULTI EXEC WATCH UNWATCH Redis 分布式锁setnx 互斥能力，，如果进程异常，没及时释放锁，造成死锁设置失效时间，看门狗守护线程，定时检测锁的失效时间，如果操作还未完成，进行自动锁续期 Redis 消息队列基于列表lpush，brpop/blpop，不能重复消费，不能广播，不能保证消费者消费者消费后是否成功处理基于sorted-set，多用来实现延迟消息队列，只能轮询，不允许重复消费消息pub/sub，订阅/发布模式，广播模式，即时发送，发布时若客户端故障，消息丢失，不能寻回；不能保证每个消费者接收的时间时一致的，出现消息积压会强制断开，导致消息丢失，适合及时通讯不适合消息存储redis5.0基于stream链表，消费者组借鉴kafka设计，有一个固定最大长度，超过会把老消息干掉 bigkey字符串类型，单个value值很大，超过10kb就算bigkey非字符串类型，元素个数过多 缺点：内存空间分布不均匀超时阻塞网络阻塞，获取bigkey，产生网络流量较大 Redis 如何解决key冲突业务隔离，key的设计，分布式锁（多个客户端并发写） 如何提高缓存命中提前加载，增加缓存的存储空间，提高缓存的数据，提高命中率，调整缓存的存储类型，提升缓存的更新频次 热点数据考虑使用缓存，不重要的点赞数数据更新之前至少读取两次 1、客户端阻塞命令，keys，smembers2、bigkey 删除 100w大概删2s3、清空库 flushall4、aof日志同步，大量写操作 同步写磁盘5、从库加载rdb 什么时候使用redis，memchached redis功能更强大，可以持久化aof，rdb redis 内存可过期，淘汰，memcached预分配管理 redis io多路复用，子任务 锁冲突；memcached 非阻塞多路复用，多线程 redis 事务，主从复制，lua mq Redis性能问题 持久化，全量复制部分复制，主节点不做持久化，从节点进行持久化操作 数据比较重要开启aof持久化，slave每秒同步一次 主从复制的流畅，同一个局域网 避免主库压力很大，增加从库 不要采用网状结构 setIfAbsent Redisson进行分布式锁 Redis 集群1、客户端分区方案，优点分区逻辑可控，缺点是需要自己处理数据路由，高可用，故障转移2、代理方案，优点是简化客户端分布式逻辑和升级维护便利，缺点加重了架构部署复杂度和性能损耗 官方解决方案：Redis Cluster分槽slot集群功能限制1、key批量操偶做支持有限，mset，mget只支持具有slot的key执行批量操作2、key事务操作支持有限，只支持多key在同一节点上的事务操作3、key作为数据分区的最小粒度，不能将一个大的键值对象如hash，list映射到不同的节点4、不支持多数据库空间，单机下Redis支持16个数据库，集群模式只能用一个数据库空间db05、复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构 参考链接分布式之redis复习精讲主从DB与cache一致性Redis协议规范（译文）Redis官方持久化Redis使用中存在的问题缓存更新套路]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】AQS(AbstractQueuedSynchronizer)队列同步器]]></title>
    <url>%2F2019%2F10%2F11%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FAQS%2F</url>
    <content type="text"><![CDATA[AQS(AbstractQueuedSynchronizer抽象队列同步器)JUC包里面的类使用继承AQS进行并发实现，子类通过继承同步器抽象方法来管理同步状态，只能在一个时刻发生阻塞，从而降低上下文切换的开销，提高了吞吐量。 状态控制：private volatile int state;使用int类型的成员变量state来表示同步状态，当state&gt;0时表示已经获取了锁，当state = 0时表示释放了锁。getState()：返回同步状态的当前值；setState(int newState)：设置当前同步状态；compareAndSetState(int expect, int update)：使用CAS设置当前状态，该方法能够保证状态设置的原子性； AQS内的CLH同步队列对同步状态的获取和释放FIFO的双向队列，AQS依赖它来完成同步状态的管理，当前线程如果获取同步状态失败时，AQS则会将当前线程已经等待状态等信息构造成一个节点（Node）并将其加入到CLH同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点唤醒（公平锁），使其再次尝试获取同步状态。 AQS使用的LockSupport对线程的阻塞和唤醒LockSupport 不可重入，一个线程连续两次调用park()，将会产生死锁，一直阻塞park()：阻塞线程，unpark()：唤醒线程 参考链接【死磕Java并发】—–J.U.C之AQSJ.U.C之AQS：同步状态的获取与释放LockSupport的park和unpark的基本使用,以及对线程中断的响应性]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】普通容器，同步容器和并发容器]]></title>
    <url>%2F2019%2F10%2F10%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FJava%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Java容器本文主要对Java中的容器进行介绍，主要分为普通容器，同步容器和并发容器 普通容器 ArrayList：适合读取O(1)，默认初始容量为10，size()是实际元素的个数 12//Default initial capacity.private static final int DEFAULT_CAPACITY = 10; 扩容方式，自动扩容还需要进行一个copy，消耗的资源较多 ，尽可能设置好初始大小 123456789101112131415private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; // 默认新容量为原来的1.5倍，old+old/2 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 若新容量比需要容量小，则以需要的容量为准 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 如果新容量比最大容量还大，则使用最大容量 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: // 以新容量的大小拷贝一个新ArrayList elementData = Arrays.copyOf(elementData, newCapacity); &#125; LinkedList 适合添加和删除 O(1)，查找O(n) HashMap 实现了Map接口，底层由数组bucket+链表(散列表)+红黑树实现，几种数据结构存的都是键值对，hashcode相同bucket位置来储存Entry对象，当出现hash冲突时使用链表存储entry插入开头，当冲突数大于8时使用红黑树存储，使用链表键值可以为null，初始容量16，当元素数量达到总容量的0.75扩容，扩容方式2的n次方 123//The default initial capacity - MUST be a power of two.static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 遍历删除1234567891011121314151617181920//listIterator&lt;String&gt; it = list.iterator(); while(it.hasNext())&#123; String x = it.next(); if(x.equals("del"))&#123; it.remove(); &#125;&#125;//mapIterator&lt;Map.Entry&lt;Integer, String&gt;&gt; it = map.entrySet().iterator(); while(it.hasNext())&#123; Map.Entry&lt;Integer, String&gt; entry = it.next(); Integer key = entry.getKey(); if(key % 2 == 0)&#123; System.out.println("To delete key " + key); it.remove(); System.out.println("The key " + + key + " was deleted"); &#125; &#125; Map相关 HashMap:内部结构是哈希表+红黑树，键和值都可以是空对象，不保证映射的顺序，多次访问，映射元素的顺序可能不同，非线程安全。默认大小为16，扩容方式，2的指数 HashTable:线程安全的HashMap，默认大小为11，扩容方式为old*2+1 LinkedHashMap:可按put顺序遍历输出。WeakHashMap:主要用来实现缓存，被WeakHashMap关联的对象在下一次JVM垃圾回收时会被回收，非线程安全。 SortedMap:键按升序排序，所有键必须实现Comparable接口。 TreeMap:内部为红黑树实现，不同步，可对Map集合中的键进行排序。 IdentityHashMap：可支持多个重复key，靠对象判断key是否相等 Set相关一个不允许重复元素的Collection，可以有一个空元素，不可随机访问包含的元素，只能用Iterator实现单向遍历，Set不同步。下面接口实现都是非安全的。HashSet: 内部数据结构是HashMap，使用HashMap的key存储元素，value全是一样的虚拟元素PRESENT，由于HashMap的特性所以HashSet元素是唯一的，元素是无序的，允许有一个null，迭代访问元素的顺序和加入的顺序不同，多次迭代访问，元素的顺序可能不同。LinkedHashSet: 基于LinkedHashMap实现，迭代访问元素的顺序和加入的顺序相同，多次迭代访问，元素的顺序不变，与LinkedHashMap访问区别：不支持按访问顺序排序，只能按插入顺序排序。TreeSet: 基于TreeMap实现，存在NavigableMap接口的一个对象m，实际上为其实现类TreeMap的实例，可以看做是NavigableMap组合TreeMap，可以对Set集合中的元素进行排序，排序后按自然升序排列元素，可传入自定义的Comparator。 如何比较两个List是否相等设定一个标记数组，标记是否找到过 如何比较两个Set元素是否相等Set不重复，先判断数量是否相等，再做一次嵌套循环，比较A中元素是否在B中 如何保证ArrayList的安全 使用Collections里面的SynchronizedList的方法，全部读写都加锁，效率不高 使用CopyOnWriteArrayList，适合读多写少的情况，读写分离，读操作不加锁，写操作使用ReentrantLock重入锁，读操作支持随机访问O(1)，保证最终一致性，不保证强一致性。在List发生变化时(增删)O(n)，都会调用Arrays.copyOf()对原数组进行复制，造成内存损耗。 如何保证Set的安全性 使用Collections里面的newSetFromMap，将ConcurrentHashMap转换为Set 使用CopyOnWriteArraySet：内部通过CopyOnWriteArrayList实现，有序，并发安全，读写分离，通过AddIfAbsent()方法保证元素不重复 同步容器 Vector Stack 继承自Vector，先进后出 HashTable 其中都是使用synchronized进行修饰，保证同一个变量只能由一个线程访问 Collections下的 List list = Collections.synchronizedList(new ArrayList());Set set = Collections.synchronizedSet(new HashSet());Map map = Collections.synchronizedMap(new HashMap()); 同步容器和并发容器的区别 同步容器，方法上都加入了synchronized进行同步控制，但是做复合操作：迭代（反复访问元素，遍历完容器中的所有元素）、跳转（根据指定的顺序找到当前元素的下一个元素）、以及条件运算时不一定安全，对一个线程来说是安全的，但是多个线程操作就会出现异常 并发容器，主要通过CAS进行并发控制，内部也可能会使用synchronized和锁进行控制 并发容器 ConcurrentHashMap 和Hashmap的存储方式一样，但是通过对数组进行加锁synchronized和使用CAS(Compare And Swap)进行并发控制 ConcurrentSkipListMap - 线程安全的有序 Map。使用跳表实现高效并发。 CopyOnWriteArrayList - 线程安全的 ArrayList CopyOnWriteArraySet - 线程安全的 Set，它内部包含了一个 CopyOnWriteArrayList，因此本质上是由 CopyOnWriteArrayList 实现 ConcurrentSkipListSet - 相当于线程安全的 TreeSet。它是有序的 Set。它由 ConcurrentSkipListMap 实现。 CopyOnWriteArraySet - 线程安全的 Set，它内部包含了一个CopyOnWriteArrayList，因此本质上是由 CopyOnWriteArrayList 实现 ConcurrentHashMap - 线程安全的 HashMap。采用分段锁实现高效并发。 ConcurrentSkipListMap - 线程安全的有序 Map。使用跳表实现高效并发。 ConcurrentLinkedQueue - 线程安全的无界队列。底层采用单链表。支持 FIFO。 ConcurrentLinkedDeque - 线程安全的无界双端队列。底层采用双向链表。支持 FIFO 和 FILO。 各种阻塞队列使用 ArrayBlockingQueue - 数组实现的阻塞队列。 LinkedBlockingQueue - 单链表实现的阻塞队列。 LinkedBlockingDeque - 双向链表实现的双端阻塞队列。 集合注意点 能用isEmpty不用size()，size()一般需要进行遍历]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】ThreadLocal]]></title>
    <url>%2F2019%2F10%2F09%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[作用及基本介绍ThreadLocal解决多线程环境成员变量的冲突问题（解决共享冲突），不是解决线程同步问题，与线程同步机制不同，线程同步是多个线程共享同一个变量（用空间换时间），而ThreadLocal是每一个线程创建一个单独的变量副本，每个线程可以独立的改变自己的变量副本，不影响其他线程 get()：返回此线程局部变量的当前线程副本中的值。initialValue()：返回此线程局部变量的当前线程的“初始值”。remove()：移除此线程局部变量当前线程的值。set(T value)：将此线程局部变量的当前线程副本中的值设置为指定值。 ThreaLocalMapThreadLocal内部还有一个静态内部类ThreadLocalMap，该内部类才是实现线程隔离机制的关键，get()、set()、remove()都是基于该内部类操作。ThreadLocalMap提供了一种用键值对方式存储每一个线程的变量副本的方法，key为当前ThreadLocal对象（实际上是指向该ThreadLocal对象的弱引用），value则是对应线程的变量副本。 对于ThreadLocal需要注意的有两点：ThreadLocal实例本身是不存储值，它只是提供了一个在当前线程中找到副本值得key。是ThreadLocal包含在Thread中，而不是Thread包含在ThreadLocal中。 为什么使用弱引用 因为如果这里使用普通的key-value形式来定义存储结构，实质上就会造成节点的生命周期与线程强绑定，只要线程没有销毁，那么节点在GC分析中一直处于可达状态，没办法被回收，而程序本身也无法判断是否可以清理节点。弱引用是Java中四档引用的第三档，比软引用更加弱一些，如果一个对象没有强引用链可达，那么一般活不过下一次GC。当某个ThreadLocal已经没有强引用可达，则随着它被垃圾回收，在ThreadLocalMap里对应的Entry的键值会失效，这为ThreadLocalMap本身的垃圾清理提供了便利。 ThreadLocalMap 的散列算法 斐波那契散列法，来保证哈希表的离散度。而它选用的乘数值即是2^32 * 黄金分割比。 父子线程如何共享变量 InheritableTableLocal ，每开一个线程就会创建新的ThreadLocalMap和Entry，将父线程的ThreadLocalMap添加到Entry中 但是使用线程池时，由于线程重复使用，不可使用这种方式，需要另外解决线程池内传递变量的问题]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】Serializable]]></title>
    <url>%2F2019%2F10%2F05%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FJava-Serializable%2F</url>
    <content type="text"><![CDATA[Java序列化，将Java对象转换为字节数组，便于存储传输 反序列化，将字节数组转换为Java对象 如果一个类能够序列化，他的子类能够序列化 如果子类实现了Serializable接口，父类没有实现，父类不能被序列化，子类可以 由static修饰的类的成员，transient修饰的对象代表对象的临时数据，不能被序列化]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】基本类型和包装类型]]></title>
    <url>%2F2019%2F10%2F05%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2F%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%8C%85%E8%A3%85%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[基本类型和包装类型 包装类型可以为null，基本类型不可以，如果数据库查询为null，但是使用基本类型接收，要进行自动拆箱，Integer转为int，抛出空指针异常 包装类型可以用于泛型，基本类型不可以 基本类型存在栈中，包装类型存储的是堆中的引用，基本类型更加高效 两个包装类型的(equals)值可能相同，但是(==)不是同一对象 当需要进行自动装箱时，如果数字在-128到127之间，会直接使用缓存中的对象，而不是重新创建一个对象由基本类型如：int转换为包装类型Integer 自动装箱，Integer.ValueOf()由包装类型如：Integer转为基本类型int 自动装箱，Integer.intValue()]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】==和equals]]></title>
    <url>%2F2019%2F10%2F05%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2F%3D%3D%E5%92%8Cequals%2F</url>
    <content type="text"><![CDATA[==对于基本数据类型来说，== 比较的是值。对于引用数据类型来说，== 比较的是对象的内存地址，因为引用类型变量存的值是对象的地址。 equalsequals() 不能用于判断基本数据类型的变量，只能用来判断两个对象是否相等。 类没有重写 equals()方法 ：通过equals()比较该类的两个对象时，等价于通过“==”比较这两个对象，使用的默认是 Object类equals()方法。类重写了 equals()方法 ：重写 equals()方法来比较两个对象中的属性是否相等；若它们的属性相等，则返回 true(即，认为这两个对象相等)。 hashcodehashCode() 的作用是获取哈希码，也称为散列码；它实际上是返回一个int整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。 如果两个对象的hashCode 值相等，那这两个对象不一定相等（哈希碰撞）。如果两个对象的hashCode 值相等并且equals()方法也返回 true，这两个对象相等。如果两个对象的hashCode 值不相等，这两个对象不相等。 为什么重写 equals() 时必须重写 hashCode() 方法？因为两个相等的对象的 hashCode 值必须是相等。也就是说如果 equals 方a法判断两个对象是相等的，那这两个对象的 hashCode 值也要相等。如果重写 equals() 时没有重写 hashCode() 方法的话就可能会导致 equals 方法判断是相等的两个对象，hashCode 值却不相等。 https://www.cnblogs.com/skywang12345/p/3324958.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【MySQL】索引，锁，InnoDB特点]]></title>
    <url>%2F2019%2F10%2F03%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMySQL-index%2F</url>
    <content type="text"><![CDATA[索引InnoDB默认索引B+树，自适应hash索引（自动创建）除了叶子节点，其他都是索引字段，叶子节点存储真实数据密集索引 ：一个索引项(1001)对应一个数据记录(1001) 稀疏索引 ： 一个索引项(1001)对应一块数据记录(1001,1002,1003) 聚集索引 ： 索引的逻辑顺序和磁盘行物理位置（数据存储位置）顺序相同(一般为主键索引，一个表只有一个，整个表成为一个索引，如果表中没有显示指定主键，则会选择表中的第一个不允许为NULL的唯一索引，如果还是没有的话，就采用Innodb存储引擎为每行数据内置的6字节ROWID作为聚集索引)，逻辑有序，数据页通过双向链表连接 非聚集索引 ： 索引的逻辑顺序和磁盘行的物理位置（数据）顺序不同(普通，唯一，全文，每个索引互相独立，给字段创建一个索引，字段中的数据就会被复制一份，生成该字段索引，查找的时候先通过该索引找到对应的主键索引，然后再通过主键索引找到对应的值) 为什么在插入时非聚集索引要更快一些，聚集索引需要先找到位置后再进行插入 覆盖(复合)索引，多个字段组成的索引，若查询时是查找这些字段的值，则不需要使用主键索引 聚集索引创建规则： 当定义了主键后，InnoDB会利用主键来生成其聚簇索引； 如果没有主键，InnoDB会选择一个非空的唯一索引来创建聚簇索引； 如果这也没有，InnoDB会隐式的创建一个自增的列来作为聚簇索引。 索引使用注意 尽量选择字段长度比较小，重复比较少的字段建立 避免在where语句后果进行null值判断，null会使索引失效 避免使用!=和&lt;&gt;，not , not in, not like, !&gt;,!&lt;，单一索引失效，复合索引还有效 避免使用or进行连接条件，如果一个有索引一个没有索引将使索引失效 前导模糊查询”%%”，”%abc”索引失效，”ab%”索引有效 不要在where里面对字段进行计算 能用between不使用in，能用distinct不用groupby 复合索引最常用的放最左边 对经常进行删除，修改，插入的表尽量少建立索引 减少使用子查询，尽量使用join代替，子查询会先生成一个临时表 Union All 、Union、Intersect、Minus区别 UNION ALL 不执行select distinct，包括重复行UNION 执行distinct，不包括重复行，进行并集操作Intersect 不包括重复行，对两个结果集进行交集操作Minus 不包括重复行，对两个结果进行差集操作必须保证两个结果集有相同的列(个数和每个列的类型) 当知道不存在重复的行时使用UNION ALL速度更快 limit 起始位置过大，加一个起始id where id&gt;n limit 10;select * from user where uid &gt;=( select uid from user order by uid limit 10000,1 ) limit 10;延迟关联子查询，子查询索引只获取一个cloumn，性能好 like 失效的原因 %是根据首字母的大小进行排序，如果%在左侧，首部字母无法排序 使用覆盖索引进行查询 索引列是查询结果， 索引下推 如果没有索引下推优化ICP，当进行索引查询时，首先根据索引查找记录，然后根据where条件过滤记录 支持ICP优化后，mysql会在去除索引的同时，判断是否可以进行where条件过滤在进行索引查询，减少回表次数，提升性能 explain type： — 找到不到笔记了，后续再加 数据库事务① Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。② Repeatable read (可重复读)：可避免脏读、不可重复读的发生。③ Read committed (读已提交)：可避免脏读的发生。④ Read uncommitted (读未提交)：最低级别，任何情况都无法保证。 脏读 ：表示一个事务能够读取另一个事务中还未提交的数据。比如，某个事务尝试插入记录 A，此时该事务还未提交，然后另一个事务尝试读取到了记录 A。 不可重复读 ：是指在一个事务内，多次读同一数据。例如事务T1在读取某一数据，而事务T2立马修改了这个数据并且提交事务给数据库，事务T1再次读取该数据就得到了不同的结果，发生了不可重复读。 不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。 幻读 ：指同一个事务内多次查询返回的结果集不一样。比如同一个事务 A 第一次查询时候有 n 条记录，但是第二次同等条件下查询却有 n+1 条记录，这就好像产生了幻觉。发生幻读的原因也是另外一个事务新增或者删除或者修改了第一个事务结果集里面的数据，同一个记录的数据内容被修改了，所有数据行的记录就变多或者变少了。 锁InnoDB支持行锁和表锁，MyISAM支持表锁表级锁：开销小，加锁快，不会出现死锁。锁定粒度大，发生锁冲突的概率最高，并发量最低。行级锁：开销大，加锁慢，会出现死锁。锁力度小，发生锁冲突的概率小，并发度最高。 乐观锁：每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在提交更新的时候会判断一下在此期间别人有没有去更新这个数据。 悲观锁：每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻止，直到这个锁被释放。 InnoDB特点自适应hash索引会监控对二级索引的查找，如果发现某一个二级索引被频繁访问，二级索引就成为一个热数据。 经常访问的二级索引数据会自动被生成到Hash索引里面去，自适应哈希索引通过缓冲池的B+树构造。不是整个表都建立索引，是对某些页建立索引，分片进行实现 限制： 只能使用等值比较 会占用缓冲池 无法用于排序 有冲突可能 人为无法干预 两次写（Double Write提高可靠性）：问题点：部分写失效，当数据正在从内存向磁盘中写一个数据页时，数据库宕机，导致只写入了部分数据，部分数据丢失。页本身已经损坏，重做日志（redo log）无效，重做日志是对页的物理修改。 解决方案：两次写，多了一个redo的副本，如果宕机可以通过副本将原来的页恢复 结构： 内存两次写缓冲 2MB磁盘共享表空间连续128页 2MB 原理 刷新缓冲池脏页，不直接写数据文件，先拷贝至内存中的两次写缓冲区 接着从两次写缓冲区分两次顺序写入磁盘共享表空间的物理磁盘中，每次写入1MB，然后马上调用fsync函数，同步磁盘，避免缓冲写带来的问题 第二步完成后，将两次写缓冲区的页离散的写入到数据文件中 这样就可以解决上文提到的部分写失效的问题，因为在磁盘共享表空间中已有数据页副本拷贝，如果数据库在页写入数据文件的过程中宕机，在实例恢复时，可以从共享表空间中找到该页副本，将其拷贝覆盖原有的数据页，再应用重做日志即可。 插入缓冲机制(提高写性能)Change Buffer：用于在对数据变更时，如果数据所在的数据页没有在 buffer pool 中的话，在不影响数据一致性的前提下，InnoDB 引擎会将对数据的操作缓存在 Change Buffer 中，这样就省去了从磁盘中读入这个数据页。 问题：辅助索引和索引不唯一时的插入效率低 解决方案： 对于非聚集类索引的插入和更新操作，不是每一次都直接插入到索引页中，而是先插入到内存中。如果索引页在缓冲池中，就直接插入，如果不在缓冲池中，就先将其躺入插入缓冲池中，然后以一定的频率和索引页合并，将同一个索引页中的锁哥插入合并到一个IO操作中。 插入缓冲的问题 数据库宕机的之后，恢复时间变长 写密集情况下 ，插入缓冲会占用过多的缓冲池内存 触发写缓存（Change Buffer）持久化操作有以下几种情况： 1、数据库空闲时，后台有线程定时持久化 2、数据库缓冲池不够用时 3、数据库正常关闭时 4、redo log 写满时 如果数据页没有在内存中，会将更新操作缓存到 change buffer 中，这样就不需要从磁盘读入这个数据页，减少了 IO 操作，提高了性能。 先将更新操作，记录在 change buffer 中，之后再进行 merge,真正进行数据更新。 merge 过程中只会将 Change Buffer 中与原始数据页有关的数据应用到原始数据页，以下三种情况会发生 merge 操作： 1、原始数据页加载到 Buffer Pool 时。 2、系统后台定时触发 merge 操作。 3、MySQL 数据库正常关闭时。 InnoDB和MyIASM区别InnoDB支持行锁和表锁，外键，数据缓存， 事务，适合插入更新，不支持全文检索，锁的粒度小，适合并发度高的情况，使用聚簇索引，更适合范围查找和排序 MyIASM支持表锁，全文检索，不支持事务，外键，在写操作是会锁定整张表，使用非聚簇索引 InnoDB锁Record Lock：单个行记录上的锁 Gap Lock：间隙锁，锁定一个范围，但不包含记录本身 Next-Key Lock：Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身。 MVCC 中使用的 InnoDB锁表的死锁，用户A访问表A，锁住了表A，然后有访问表B；用户B访问表B，锁住了表B，又要访问表A。此时用户A等待B释放，B等待A释放，产生死锁 避免同时锁定两个资源，按顺序处理 行级锁死锁 事务中没有索引条件的查询，全表扫描，上升为全表记录锁定，多个这样的事务知行时会产生死锁和阻塞 两个事务分别想拿到对方持有的锁，互相等待，产生死锁 同一个事务，对索引加锁顺序不一致可能导致死锁 参考链接MySQL性能优化MySQL优化有理有据SQL语句优化]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Spring学习笔记2】常用的各种注解及替代xml配置的作用]]></title>
    <url>%2F2019%2F10%2F02%2FSpring%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2FSpring%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[123&lt;bean id="" class="" scope="" init-method="" destroy-method=""&gt; &lt;property name="" value="" | ref=""&gt;&lt;/property&gt; &lt;/bean&gt; 用于创建对象 他们的作用就和在XML配置文件中编写一个标签实现的功能是一样的Component: 作用：用于把当前类对象存入spring容器中 属性： value：用于指定bean的id。当我们不写时，它的默认值是当前类名，且首字母改小写。Controller：一般用在表现层Service：一般用在业务层Repository：一般用在持久层以上三个注解他们的作用和属性与Component是一模一样。他们三个是spring框架为我们提供明确的三层使用的注解，使我们的三层对象更加清晰 用于注入数据 他们的作用就和在xml配置文件中的bean标签中写一个标签的作用是一样的@Autowired: 作用：自动按照类型注入。只要容器中有唯一的一个bean对象类型和要注入的变量类型匹配，就可以注入成功 如果ioc容器中没有任何bean的类型和要注入的变量类型匹配，则报错。 如果Ioc容器中有多个类型匹配时： 出现位置： 可以是变量上，也可以是方法上 细节： 在使用注解注入时，set方法就不是必须的了。@Qualifier: 作用：在按照类中注入的基础之上再按照名称注入。它在给类成员注入时不能单独使用（需要和Autowired一起使用）。但是在给方法参数注入时可以 属性：value：用于指定注入bean的id。 @Resource 作用：直接按照bean的id注入。它可以独立使用属性： name：用于指定bean的id。以上三个注入都只能注入其他bean类型的数据，而基本类型和String类型无法使用上述注解实现。 另外，集合类型的注入只能通过XML来实现。@Value 作用：用于注入基本类型和String类型的数据 属性： value：用于指定数据的值。它可以使用spring中SpEL(也就是spring的el表达式） SpEL的写法：${表达式} 用于改变作用范围 他们的作用就和在bean标签中使用scope属性实现的功能是一样的 @Scope 作用：用于指定bean的作用范围 属性： value：指定范围的取值。常用取值：singleton prototype 和生命周期相关 他们的作用就和在bean标签中使用init-method和destroy-methode的作用是一样的 @PreDestroy 作用：用于指定销毁方法 @PostConstruct 作用：用于指定初始化方法 配置类里面常用的注解 @Configuration 作用：指定当前类是一个配置类 细节：当配置类为AnnotationConfigApplicationContext对象创建的参数时，该注解可以不写。@ComponentScan 作用：用于通过注解指定spring在创建容器时要扫描的包 属性： value：它和basePackages的作用是一样的，都是用于指定创建容器时要扫描的包。 我们使用此注解就等同于在xml中配置了:&lt;context:component-scan base-package=&quot;com.example&quot;&gt;&lt;/context:component-scan&gt;@Bean 作用：用于把当前方法的返回值作为bean对象存入spring的ioc容器中 属性: name:用于指定bean的id。当不写时，默认值是当前方法的名称 细节： 当我们使用注解配置方法时，如果方法有参数，spring框架会去容器中查找有没有可用的bean对象。 查找的方式和Autowired注解的作用是一样的@Import 作用：用于导入其他的配置类 属性： value：用于指定其他配置类的字节码。 当我们使用Import的注解之后，有Import注解的类就父配置类，而导入的都是子配置类@PropertySource 作用：用于指定properties文件的位置 属性： value：指定文件的名称和路径。 关键字：classpath，表示类路径下]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Spring学习笔记1】IOC的创建和Bean的管理]]></title>
    <url>%2F2019%2F10%2F02%2FSpring%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2FSpringIOCAOP%2F</url>
    <content type="text"><![CDATA[Spring 是什么分层的轻量型开源框架，以 IoC（Inverse Of Control：反转控制）和 AOP（Aspect Oriented Programming：面向切面编程）为内核 优势 方便解耦，简化开发通过 Spring提供的 IoC容器，可以将对象间的依赖关系交由 Spring进行控制，避免硬编码所造成的过度程序耦合。用户也不必再为单例模式类、属性文件解析等这些很底层的需求编写代码，可以更专注于上层的应用。 AOP 编程的支持通过 Spring的 AOP 功能，方便进行面向切面的编程，许多不容易用传统OOP 实现的功能可以通过 AOP 轻松应付。 声明式事务的支持可以将我们从单调烦闷的事务管理代码中解脱出来，通过声明式方式灵活的进行事务的管理，提高开发效率和质量。 方便集成各种优秀框架Spring可以降低各种框架的使用难度， 提供了对各种优秀框架 （Struts、 Hibernate、 Hessian、 Quartz等）的直接支持。 IOC控制反转，将主动创建对象的权利交给Spring框架来管理(在当前类需要用到其他类的对象，由Spring创建，只需要在配置文件中声明依赖关系的维护，不用考虑对象是如何创建出来的)目的：降低耦合内部通过工厂模式进行Bean的创建，通过一个Map进行Bean的管理 依赖注入能注入的数据：有三类 基本类型和String其他bean类型（在配置文件中或者注解配置过的bean）复杂类型/集合类型 注入的方式：有三种 第一种：使用构造函数提供第二种：set方法注入第三种：使用接口注入 构造函数注入 使用的标签:constructor-arg标签中的属性type：用于指定要注入的数据的数据类型，该数据类型也是构造函数中某个或某些参数的类型index：用于指定要注入的数据给构造函数中指定索引位置的参数赋值。索引的位置是从0开始name：用于指定给构造函数中指定名称的参数赋值 常用的 =============以上三个用于指定给构造函数中哪个参数赋值value：用于提供基本类型和String类型的数据ref：用于指定其他的bean类型数据。它指的就是在spring的Ioc核心容器中出现过的bean对象优势：在获取bean对象时，注入数据是必须的操作，否则对象无法创建成功。弊端：改变了bean对象的实例化方式，使我们在创建对象时，如果用不到这些数据，也必须提供。1234567 &lt;bean id="" class=""&gt; &lt;constructor-arg name="name" value=""&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="birthday" ref="now"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 配置一个日期对象 --&gt;&lt;bean id="now" class="java.util.Date"&gt;&lt;/bean&gt; Set方法注入 标签：property出现的位置：bean标签的内部标签的属性name：用于指定注入时所调用的set方法名称value：用于提供基本类型和String类型的数据ref：用于指定其他的bean类型数据。它指的就是在spring的Ioc核心容器中出现过的bean对象优势： 创建对象时没有明确的限制，可以直接使用默认构造函数弊端： 如果有某个成员必须有值，则获取对象是有可能set方法没有执行。1234567891011121314&lt;bean id="" class="" scope="singleton"&gt;&lt;!--用于给List结构集合注入的标签： list array set用于给Map结构集合注入的标签: map props结构相同，标签可以互换--&gt; &lt;property name="myList"&gt; &lt;array&gt; &lt;value&gt;AAA&lt;/value&gt; &lt;value&gt;BBB&lt;/value&gt; &lt;value&gt;CCC&lt;/value&gt; &lt;/array&gt; &lt;/property&gt;&lt;/bean&gt; 接口注入一个实现了接口的类A，必须以接口的形式注入到目标B中，如果有多个实现类时需要指定是哪一个实现类，使用@Autowired+@Qualifier或者@Resource，按名称进行注入 Spring循环依赖Spring IOC 容器，默认的单例Bean，属性互相引用（A依赖B，B又依赖A） 解决使用setter 注入，并且是singleton单例的 Spring 内部通过3级缓存进行解决，DefalutSingletonBeanRegistry，里面有3个Map 一级缓存（单例池）singletonObjects：存放已经完成的Bean对象 二级缓存earlySingletonObjects：存放早期暴露出来的Bean，生命周期还未结束，属性还未填充 三级缓存singletonFactories，存放可以生成Bean的工厂 A 创建需要B ，A 将自己放到三级缓存中，去实例化B B实例化的时候需要A，B先查一级缓存，二级缓存，没有找到A ，再查三级缓存，找到A ，B初始化完毕，将自己放到一级缓存，并将A放入二级缓存，删除三级缓存的A 继续创建A，从一级缓存拿出B，完成创建，并把自己放到一级缓存中 三级缓存主要处理aop代理对象，二级缓存也可以解决循环依赖，但是存储的是原型对象，aop失效 ApplicationContext的三个常用实现类 ClassPathXmlApplicationContext：它可以加载类路径下的配置文件，要求配置文件必须在类路径 下。不在的话，加载不了。(更常用) FileSystemXmlApplicationContext：它可以加载磁盘任意路径下的配置文件(必须有访问权限） AnnotationConfigApplicationContext：它是用于读取注解创建容器的 ApplicationContext和BeanFactory的区别 BeanFactory： Spring最底层的接口，各种Bean的定义，配置初始化，实例化，控制bean的生命周期 使用延迟加载，读取配置文件时不会创建对象，使用时才会创建 ApplicationContext： BeanFactory的派生，可进行更多的扩展，继承messagesource 支持国际化，统一资源文件访问，同时加载多个配置文件，载入多个上下文使每个上下文专注特定层次容器启动时，读取配置文件后一次性创建所有的Bean，有利于发现配置错误，但占用过多的内存空间 区别：BeanFactory 通常以编程方式创建，ApplicationContext 以声明方式创建BeanFactory 延迟加载(创建多例对象使用)，ApplicationContext 立即加载(创建单例对象使用) 都支持BeanPostProcessor、BeanFactoryPostProcess，BeanFactory需要手动注册，applicationContext自动注册 FactoryBeanSpring提供了两种类型的Bean，一种是普通通过getBean()获取该Bean的实际类型，另一种是FactoryBean，通过getBean()获得的是该工厂产生的Bean的实例FactoryBean是一个Bean，实现了FactoryBean的类能够改变Bean，通过自己定义的方式进行Bean的注册。三个重写的方法：getObject()：返回需要注册到Spring容器中去的bean实体getObjectType()：返回注册的这个Object的具体类型isSingleton()：返回这个bean是不是单例的，如果是，那么Spring容器全局将只保持一个该实例对象，否则每次getBean都将获取到一个新的该实例对象 Spring对Bean的管理细节创建Bean的三种方式： 使用默认构造函数创建，在Spring的配置文件中使用bean标签，配以id和class属性之后，且没有其他属性和标签时,采用的就是默认构造函数创建bean对象.此时如果类中没有默认构造函数，则对象无法创建。 1&lt;bean id="" class=""&gt;&lt;/bean&gt; 使用普通工厂中的方法创建对象（使用某个类中的方法创建对象，并存入spring容器） 1&lt;bean id="" factory-bean="" factory-method="" &gt;&lt;/bean&gt; 使用工厂中的静态方法创建对象（使用某个类中的静态方法创建对象，并存入spring容器) 1&lt;bean id="" class="" factory-method="" &gt;&lt;/bean&gt; bean标签的scope属性： 作用：用于指定bean的作用范围 取值： 常用的就是单例的和多例的 singleton：单例的（默认值）prototype：多例的request：作用于web应用的请求范围session：作用于web应用的会话范围global-session：作用于集群环境的会话范围（全局会话范围），当不是集群环境时，它就是session bean对象的生命周期单例对象 出生：当容器创建时对象出生（解析完配置文件，立即创建）活着：只要容器还在，对象一直活着死亡：容器销毁，对象消亡总结：单例对象的生命周期和容器相同 多例对象 出生：当我们使用对象时spring框架为我们创建（使用时创建，延迟创建）活着：对象只要是在使用过程中就一直活着。死亡：当对象长时间不用，且没有别的对象引用时，由Java的垃圾回收器回收 AOP将与业务逻辑无关的代码如日志，权限控制分离，减少系统重复代码，降低耦合，便于扩展和维护 基于动态代理，如果代理对象实现了某个接口，则使用JDK的动态代理创建代理对象 如果代理对象没有实现接口的对象，就使用CGlib动态代理生成一个被代理对象的子类作为代理 Spring AOP和AspectJ AOP SpringAOP 运行时增强 AspectJ 编译时增强 基于代理 基于字节码操作 性能一般 性能更好 AOP 底层时如何进行代理 AOP通过预编译方式和运行期动态代理实现程序功能 PS.解耦的思路： 第一步：使用反射来创建对象，而避免使用new关键字。 第二步：通过读取配置文件来获取要创建的对象全限定类名。]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【MySQL】char和varchar的区别]]></title>
    <url>%2F2019%2F09%2F29%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMySQL-1%2F</url>
    <content type="text"><![CDATA[MySQL中char和varcharchar长度不变，长度不足时会补空格，取出数据时也会有空格需要进行trim，存取效率要高，英文1字节，汉字2字节 varchar 长度不定，如果长度不足，长度会自动转换，更节省空间，英文汉字都是2字节 undo log、redo log 和bin log redo log 物理日志，大小固定循环写，空间一定会用完，通过write pos和check point搭配使用，innodb特有，记录某个数据页上做了什么修改，不记录更新后的状态；预写式 mysql 每知行一条DML语句，先将记录写入redo log buffer，后续某个时间点再一次性将多个操作记录写入到redo log file，通过redo log 实现事务的持久性，作为服务器异常宕机后事务数据自动恢复使用 redolog buffer ，innodb_flush_log_at_trx_commit参数设置 0 每秒写入os buffer 并刷到磁盘 ，延迟写，可能会丢失1s的数据 1 每次提交时写入osbuffer 并刷到磁盘，实时写，实时刷，io性能较差 2 每次提交时吸入os buffer，每秒调用fsync刷到磁盘，实时写，延时刷 binlog 二进制的形式记录语句的原始逻辑，记录变动的过程，追加写，写到一定大小切换下一个，不会覆盖。 有3种模式 statement 格式的话是记 sql 语句，日志量小，默认 row 格式会记录行的内容，记两条，更新前和更新后都有，能完全实现主从数据同步和数据恢复。会产生大量日制 mixed 两种方式混合使用，一般使用statement模式保存binlog，对statement模式无法复制的操作使用row模式 初始化从库时，从库会从主库拉数据，建立连接之后，主库会将binlog 推送给从库 作为主从复制和数据恢复使用，没有crash-safe能力，不能保证： 所有已经提交的事务的数据仍然存在 所有没有提交的事务的数据自动回滚 undo log 回滚日志，记录事务开始前的状态，用于事务失败时的回滚操作。undolog 也会产生redo log，也要实现持久性保护 undo log 事务开始前产生，事务提交后，先放入删除列表通过后台线程purge thread 进行回收处理 count(*) 和 count(1)和count(列名)区别 执行效果上 ：count(*)包括了所有的列，相当于行数，在统计结果的时候， 不会忽略列值为NULLcount(1)包括了忽略所有列，用1代表代码行，在统计结果的时候，不会忽略列值为NULLcount(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数， 即某个字段值为NULL时，不统计。 执行效率上：count(*)=count(1)&gt;count(列) 在线修改大表 执行时间不可预估，时间较长 修改表结构时表级锁，影响表写入操作 导致数据库cpu，io性能消耗，使mysql 服务器性能较低 在线修改大表结构容易导致主从延时，影响业务读取 online-schema-change工具]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Spring学习笔记3】SpringAOP动态代理JDK和cglib及ApsectJ]]></title>
    <url>%2F2019%2F09%2F13%2FSpring%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2FSpringAOP%2F</url>
    <content type="text"><![CDATA[动态代理： 特点：字节码随用随创建，随用随加载 作用：不修改源码的基础上对方法增强 分类： 基于接口的动态代理 基于子类的动态代理 基于子类的动态代理： 涉及的类：Enhancer 提供者：第三方cglib库 如何创建代理对象： 使用Enhancer类中的create方法 创建代理对象的要求： 被代理类不能是最终类 create方法的参数： Class：字节码 它是用于指定被代理对象的字节码。 callback：用于提供增强的代码 它是让我们写如何代理。我们一般都是些一个该接口的实现类，通常情况下都是匿名内部类，但不是必须的。 此接口的实现类都是谁用谁写。 我们一般写的都是该接口的子接口实现类：MethodInterceptor 静态代理是由自己或工具创建源代码，在程序运行前已经存在.class文件，一个代理类只能对一个业务接口实现类包装，会有很多的重复代码。 JDK动态代理利用拦截器加反射机制(invoke)生成一个实现代理接口的匿名内部类，只能针对接口，所代理的类必须实现接口 UserService userService = (UserService) jdkProxy.getProxy(new UserServiceImpl()); 通过接口实现动态代理12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273方法1:1.实现自己的代理类import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method; public class TestInvocationHandler implements InvocationHandler &#123; private Object target; TestInvocationHandler() &#123; super(); &#125; TestInvocationHandler(Object target) &#123; super(); this.target = target; &#125; @Override public Object invoke(Object o, Method method, Object[] args) throws Throwable &#123; //控制不同方法进行进行不同的代理 if("getName".equals(method.getName()))&#123; System.out.println("++++++before " + method.getName()); Object result = method.invoke(target, args); System.out.println("++++++after " + method.getName()); return result; &#125;else&#123; Object result = method.invoke(target, args); return result; &#125; &#125;&#125;2. 使用代理// 1、生成$Proxy0的class文件 System.getProperties().put("sun.misc.ProxyGenerator.saveGeneratedFiles", "true"); // 2、获取动态代理类Class proxyClazz = Proxy.getProxyClass(ITest.class.getClassLoader(),ITest.class);// 3、获得代理类的构造函数，并传入参数类型InvocationHandler.classConstructor constructor = proxyClazz.getConstructor(InvocationHandler.class);// 4、通过构造函数来创建动态代理对象，将自定义的InvocationHandler实例传入ITest iTest = (ITest) constructor.newInstance(new TestInvocationHandler(new TestImpl()));// 5、通过代理对象调用目标方法ITest.getName();---方法2:IProducer proxyProducer = (IProducer) Proxy.newProxyInstance(producer.getClass().getClassLoader(),producer.getClass().getInterfaces(),new InvocationHandler() &#123; /** * 作用：执行被代理对象的任何接口方法都会经过该方法 * 方法参数的含义 * @param proxy 代理对象的引用 * @param method 当前执行的方法 * @param args 当前执行方法所需的参数 * @return 和被代理对象方法有相同的返回值 * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //提供增强的代码 Object returnValue = null; //1.获取方法执行的参数 Float money = (Float)args[0]; //2.判断当前方法是不是销售 if("saleProduct".equals(method.getName())) &#123; returnValue = method.invoke(producer, money*0.8f); &#125; return returnValue; &#125;&#125;);proxyProducer.saleProduct(10000f); cglib动态代理针对类实现动态代理，底层使用asm来对父类字节码进行修改，对指定的类生成一个子类，覆盖业务方法实现代理。final类不能被继承，所以不能对final类进行代理。核心类： net.sf.cglib.proxy.Enhancer – 主要的增强类net.sf.cglib.proxy.MethodInterceptor – 主要的方法拦截类，它是Callback接口的子接口，需要用户实现net.sf.cglib.proxy.MethodProxy – JDK的java.lang.reflect.Method类的代理类，可以方便的实现对源对象方法的调用,如使用：Object o = methodProxy.invokeSuper(proxy, args);//虽然第一个参数是被代理对象，也不会出现死循环的问题。 通过cglib实现动态代理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//方法1:实现MethodInterceptor方法，创建代理类public class BookFacadeCglib implements MethodInterceptor &#123; private Object target;//业务类对象，供代理方法中进行真正的业务方法调用// 实现回调方法 public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; System.out.println("预处理——————"); proxy.invokeSuper(obj, args); //调用业务类（父类中）的方法 System.out.println("调用后操作——————"); return null; &#125; 调用过程// 通过CGLIB动态代理获取代理对象的过程Enhancer enhancer = new Enhancer();// 设置enhancer对象的父类enhancer.setSuperclass(HelloService.class);// 设置enhancer的回调对象enhancer.setCallback(new MyMethodInterceptor());// 创建代理对象HelloService proxy= (HelloService)enhancer.create();// 通过代理对象调用目标方法proxy.sayHello();//方法2:Producer cglibProducer = (Producer)Enhancer.create(producer.getClass(), new MethodInterceptor() &#123; /** * 执行北地阿里对象的任何方法都会经过该方法 * @param proxy * @param method * @param args * 以上三个参数和基于接口的动态代理中invoke方法的参数是一样的 * @param methodProxy ：当前执行方法的代理对象 * @return * @throws Throwable */ @Override public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; //提供增强的代码 Object returnValue = null; //1.获取方法执行的参数 Float money = (Float)args[0]; //2.判断当前方法是不是销售 if("saleProduct".equals(method.getName())) &#123; returnValue = method.invoke(producer, money*0.8f); &#125; return returnValue; &#125;&#125;);cglibProducer.saleProduct(12000f); 默认JdkDynamicAopProxy和CglibAopProxy的区别 代理类实现接口时，默认使用jdk动态代理，可强制使用cglib代理强制使用cglib：1.1 添加CGLIB库，SPRING_HOME/cglib/*.jar1.2 在spring配置文件中加入&lt;aop:aspectj-autoproxy proxy-target-class=”true” /&gt; 当代理类没有实现接口时，只能使用cglib代理 AspectJ将问题的处理放到一个切面，集中处理，编译时织入 连接点（Joinpoint）：程序执行的某个特定位置（如：某个方法调用前、调用后，方法抛出异常后）。一个类或一段程序代码拥有一些具有边界性质的特定点，这些代码中的特定点就是连接点。Spring仅支持方法的连接点。 切点（Pointcut）：如果连接点相当于数据中的记录，那么切点相当于查询条件，一个切点可以匹配多个连接点。Spring AOP的规则解析引擎负责解析切点所设定的查询条件，找到对应的连接点。 增强（Advice）：增强是织入到目标类连接点上的一段程序代码。Spring提供的增强接口都是带方位名的，如：BeforeAdvice、AfterReturningAdvice、ThrowsAdvice等。 引介（Introduction）：引介是一种特殊的增强，它为类添加一些属性和方法。这样，即使一个业务类原本没有实现某个接口，通过引介功能，可以动态的未该业务类添加接口的实现逻辑，让业务类成为这个接口的实现类。 织入（Weaving）：织入是将增强添加到目标类具体连接点上的过程 AOP有三种织入方式：①编译期织入：需要特殊的Java编译期（例如AspectJ的ajc）；②装载期织入：要求使用特殊的类加载器，在装载类的时候对类进行增强；③运行时织入：在运行时为目标类生成代理实现增强。Spring采用了动态代理的方式实现了运行时织入，而AspectJ采用了编译期织入和装载期织入的方式。 切面（Aspect）：切面是由切点和增强（引介）组成的，它包括了对横切关注功能的定义，也包括了对连接点的定义。 AspectJ实际使用xml添加配置1234&lt;!--扫描包下的所有注解--&gt;&lt;context:component-scan base-package="com.example"/&gt;&lt;!-- 使切面开启自动代理 --&gt;&lt;aop:aspectj-autoproxy&gt;&lt;/aop:aspectj-autoproxy&gt; 自己的切面12345678910111213141516171819202122232425262728293031323334353637383940@Aspect@Componentpublic class MyAspect &#123; // 要求：方法必须是private，没有值，名称自定义，没有参数 @Pointcut("execution(*com.example.dao..*.*(..))") private void myPointCut() &#123; &#125; // 前置通知 @Before("myPointCut()") public void myBefore(JoinPoint joinPoint) &#123; System.out.print("前置通知，目标："); System.out.print(joinPoint.getTarget() + "方法名称:"); System.out.println(joinPoint.getSignature().getName()); &#125; // 后置通知 @AfterReturning(value = "myPointCut()") public void myAfterReturning(JoinPoint joinPoint) &#123; System.out.print("后置通知，方法名称："+joinPoint.getSignature().getName()); &#125; // 环绕通知 @Around("myPointCut()") public Object myAround(ProceedingJoinPoint proceedingJoinPoint) throws Throwable &#123; System.out.println("环绕开始"); // 开始 Object obj = proceedingJoinPoint.proceed(); // 执行当前目标方法 System.out.println("环绕结束"); // 结束 return obj; &#125; // 异常通知 @AfterThrowing(value = "myPointCut()", throwing = "e") public void myAfterThrowing(JoinPoint joinPoint, Throwable e) &#123; System.out.println("异常通知" + "出错了" + e.getMessage()); &#125; // 最终通知 @After("myPointCut()") public void myAfter() &#123; System.out.println("最终通知"); &#125;&#125; 参考资料CGLIB动态代理实现原理JDK动态代理Java动态代理的两种实现方法动态代理的不同实现Java动态代理之jdk和cglib的两种实现spring(二) AOP之AspectJ框架的使用Spring使用AspectJ开发AOP：基于XML和基于AnnotationJDK代理、CGLIB、AspectJ代理分析比较]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring七大模块]]></title>
    <url>%2F2019%2F06%2F28%2FSpring%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2FSpring%E4%B8%83%E5%A4%A7%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[Spring IOC核心容器包含BeanFactory，负责生产和管理Bean，使用IOC将将应用的配置和依赖性规范与实际的应用程序代码分开 Spring AOP面向切面，通过动态代理，将与业务逻辑无关的代码分离 Spring Context应用上下文，为Spring框架提供上下文信息，继承BeanFactory，添加了事件处理、国际化、资源装载、透明装载、以及数据校验等功能 Spring Dao将业务逻辑代码和数据库交互的代码分离，简化数据库连接及异常处理等 Spring ORM对象映射关系，将dao里面的类和数据库的表进行关联映射 Spring Web建立在SpringContext基础之上，提供了Servlet监听器的Context和Web应用的上下文 Spring MVCSpring核心功能之上，拥有Spring框架的所有特性，能够适应多种多视图、模板技术、国际化和验证服务，实现控制逻辑和业务逻辑的清晰分离]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】ThreadPool的一点一滴]]></title>
    <url>%2F2019%2F06%2F09%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FThreadPool%2F</url>
    <content type="text"><![CDATA[线程池作用：减少对线程的创建和销毁，方便对线程进行管理好处： 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁进行的资源消耗 提高响应速度。当任务到达时，不用创建新的线程就能直接从线程池取出线程进行执行 提高线程的可管理性。可对线程进行统一分配、调优和监控 ThreadPool的参数 源码如上图 corePoolSize：核心线程数 核心线程会一直存活，即使没有任务需要执行当线程数小于核心线程数时（还未满，就会一直增），即使有线程空闲，线程池也会优先创建新线程处理设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭 maximumPoolSize：最大的线程数 corePoolSize&lt;线程数&lt;maximumPoolSize，且任务队列已满时。线程池会创建新线程来处理任务，直到线程数量达到maximumPoolSize当线程数已经=maximumPoolSize，且任务队列已满时，线程池会拒绝处理任务而抛出异常 keepAliveTime：线程空闲时间 当线程空闲时间达到keepAliveTime时，线程会被销毁，直到线程数量=corePoolSize 如果allowCoreThreadTimeout=true，则会直到线程数量=0（这个特性需要注意） unit：空闲时间单位 BlockingQueue workQueue ：任务队列 当核心线程数达到最大时，新任务会放在队列中排队等待执行 ArrayBlockingQueue：基于数组结构的有界阻塞队列，FIFO。 LinkedBlockingQueue：基于链表结构的有界阻塞队列，FIFO。默认MAX.Integer SynchronousQueue：不存储元素的阻塞队列，每个插入操作都必须等待一个移出操作，反之亦然。 PriorityBlockingQueue：具有优先界别的阻塞队列。 ThreadFactory threadFactory 创建线程的工厂 RejectedExecutionHandler handler：拒绝策略 两种情况会拒绝处理任务： 1、当线程数已经达到maxPoolSize，且任务队列已满时，会拒绝新任务 2、当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务（并不是立马停止，而是执行完再停止）。 若拒绝后，此时，线程池会调用rejectedExecutionHandler来处理这个任务。如果没有设置，默认值是AbortPolicy，会抛出异常 hreadPoolExecutor类有几个内部实现类来处理这类情况： 1：AbortPolicy 丢弃任务，抛运行时异常 2：CallerRunsPolicy 执行任务（这个策略重试添加当前的任务，他会自动重复调用 execute() 方法，直到成功） 如果执行器已关闭,则丢弃. 3：DiscardPolicy 对拒绝任务直接无声抛弃，没有异常信息 4：DiscardOldestPolicy 对拒绝任务不抛弃，而是抛弃队列里面等待最久的（队列头部的任务将被删除）一个线程，然后把拒绝任务加到队列（Queue是先进先出的任务调度算法，具体策略会咋下面有分析）（如果再次失败，则重复此过程） 5：实现RejectedExecutionHandler接口，可自定义处理器（可以自己实现然后set进去） 线程池数量 CPU 密集型任务：N（CPU 核心数）+1，多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响，能够充分利用CPU的空闲时间 IO 密集型：2N 1线程数 =N（CPU 核数）*（1+ 0 [WT（线程等待时间）]/36788ms[ST（线程时间运行时间）]） 线程池的处理流程 如果此时线程池中的数量小于 corePoolSize ，即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。（需获取全局锁） 如果此时线程池中的数量等于 corePoolSize ，但是缓冲队列 workQueue 未满，那么任务被放入缓冲队列。 如果此时线程池中的数量大于 corePoolSize ，缓冲队列 workQueue 满，并且线程池中的数量小于maximumPoolSize ，建新的线程来处理被添加的任务。（需获取全局锁） 如果此时线程池中的数量大于 corePoolSize ，缓冲队列 workQueue 满，并且线程池中的数量等于maximumPoolSize ，那么通过 handler 所指定的拒绝策略来处理此任务。 Executor框架提供了三种线程池 Executors.newFixedThreadPool(int); //创建固定容量大小的缓冲池 corePoolSize 和 maximumPoolSize都设置为创建FixedThreadPool时指定的参数nThreads，意味着当线程池满时且阻塞队列也已经满时，如果继续提交任务，则会直接走拒绝策略，该线程池不会再新建线程来执行任务，而是直接走拒绝策略。FixedThreadPool使用的是默认的拒绝策略，即AbortPolicy，则直接抛出异常。 keepAliveTime设置为0L，表示空闲的线程会立刻终止。 workQueue则是使用LinkedBlockingQueue，但是没有设置范围，那么则是最大值（Integer.MAX_VALUE），这基本就相当于一个无界队列了。使用该“无界队列”则会带来哪些影响呢？当线程池中的线程数量等于corePoolSize 时，如果继续提交任务，该任务会被添加到阻塞队列workQueue中，当阻塞队列也满了之后，则线程池会新建线程执行任务直到maximumPoolSize。由于FixedThreadPool使用的是“无界队列”LinkedBlockingQueue，那么maximumPoolSize参数无效，同时指定的拒绝策略AbortPolicy也将无效。而且该线程池也不会拒绝提交的任务，如果客户端提交任务的速度快于任务的执行，那么keepAliveTime也是一个无效参数。 Executors.newSingleThreadExecutor(); //创建容量为1的缓冲池 作为单一worker线程的线程池，SingleThreadExecutor把corePool和maximumPoolSize均被设置为1，和FixedThreadPool一样使用的是无界队列LinkedBlockingQueue,所以带来的影响和FixedThreadPool一样，如果把这个当作全局线程池，可以很好实现异步，并且还能保证任务的顺序执行，进而达到消峰的效果 Executors.newCachedThreadPool(); //创建一个缓冲池，缓冲池容量大小为Integer.MAX_VALUE CachedThreadPool的corePool为0，maximumPoolSize为Integer.MAX_VALUE，这就意味着所有的任务一提交就会加入到阻塞队列中。keepAliveTime这是为60L，unit设置为TimeUnit.SECONDS，意味着空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被终止。阻塞队列采用的SynchronousQueue，而我们在【死磕Java并发】—-J.U.C之阻塞队列：SynchronousQueue中了解到SynchronousQueue是一个没有元素的阻塞队列，加上corePool = 0 ，maximumPoolSize = Integer.MAX_VALUE，这样就会存在一个问题，如果主线程提交任务的速度远远大于CachedThreadPool的处理速度，则CachedThreadPool会不断地创建新线程来执行任务，这样有可能会导致系统耗尽CPU和内存资源，所以在使用该线程池是，一定要注意控制并发的任务数，否则创建大量的线程可能导致严重的性能问题。 ScheduledThreadPoolExecutor 延时和周期的线程池ScheduledThreadPoolExecutor，继承ThreadPoolExecutor且实现了ScheduledExecutorService接口，它就相当于提供了“延迟”和“周期执行”功能的ThreadPoolExecutor。在JDK API中是这样定义它的：ThreadPoolExecutor，它可另行安排在给定的延迟后运行命令，或者定期执行命令。需要多个辅助线程时，或者要求 ThreadPoolExecutor 具有额外的灵活性或功能时，此类要优于 Timer。 一旦启用已延迟的任务就执行它，但是有关何时启用，启用后何时执行则没有任何实时保证。按照提交的先进先出 (FIFO) 顺序来启用那些被安排在同一执行时间的任务。1234567891011121314151617181920212223public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, RejectedExecutionHandler handler)&#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), handler);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler)&#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler);&#125; 如何将一个线程加入到线程池中 execute()，无返回值，不知道是否执行成功 submit()，返回值为Future，根据Future对象可判断线程池的状态 invokeAny()，方法阻塞，提交多个任务，如果任务有一个完成就返回List\，其他任务中断 invokeAll()，方法阻塞，提交多个任务，当任务全部执行完才返回，可设置超时时间，超时返回 如何关闭线程池 shutdown()，一旦在线程池上调用 shutdown 方法之后，线程池便不能再接受新的任务；如果此时还向线程池提交任务，那么将会抛出 RejectedExecutionException 异常。之后线程池不会立刻关闭，直到之前已经提交到线程池中的所有任务（包括正在运行的任务和在队列中等待的任务）都已经处理完成，才会关闭。 shutdownNow()，立即关闭线程， 当前在线程池中运行的任务会全部被取消，然后返回线程池中所有正在等待的任务。 CompletableFuture 进行异步编排方法： thenRun：ACompletableFuture任务完成，就开始thenRun任务B thenAccept：获取A线程结果，开始B任务，无返回值 thenApply：获取上A线程返回的结果，开始执行B线程，并返回当前线程的结果 带Async 的都是开启新线程异步，不带的就是公用 thenAfterBoth，A,B完成开始C，无返回值 thenAcceptBoth：获取A，B的返回值，并进行C thenCombine：AB完成，获取AB返回值，进行C 并返回结果 多任务组合 allOf：任务全部完成后执行，allOf.get()进行阻塞，保证任务全部执行 anyOf：有一个执行完就执行 参考：https://cloud.tencent.com/developer/article/1497458http://cmsblogs.com/?p=2448]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【分布式事务】Seata]]></title>
    <url>%2F2019%2F05%2F20%2F%E4%B8%AD%E9%97%B4%E4%BB%B6%2Fseata%2F</url>
    <content type="text"><![CDATA[seata]]></content>
  </entry>
  <entry>
    <title><![CDATA[Mybatis分页]]></title>
    <url>%2F2019%2F04%2F20%2FSpring%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2FMybatis%E5%88%86%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[使用Mybatis进行分页总结 使用sql进行分页通过limit，offset进行分页，每个页面分页都需要自己写sql，需要总数时要再另写sql进行统计，并且当limit起始位置过大，查询也会很慢解决办法：当limit 起始位置过大，加一个起始id where id&gt;n limit 10;select * from user where uid &gt;=( select uid from user order by uid limit 10000,1 ) limit 10;延迟关联子查询，子查询索引只获取一个cloumn，性能好 使用拦截器分页通过拦截器，拦截方法，加入自己的逻辑代码。对于Executor，Mybatis有以下几种实现，BatchExeutor、ReuseExecutor、SimpleExecutor和CachingExecutor。建立自己的拦截器，拦截Executor的query方法，实现自己的query方法，然后选择是否继续执行原来的query方法。Interceptor接口 对于拦截器Mybatis为我们提供了一个Interceptor接口，通过实现该接口就可以定义我们自己的拦截器。我们先来看一下这个接口的定义： 12345678910111213package org.apache.ibatis.plugin;import java.util.Properties;public interface Interceptor &#123;Object intercept(Invocation invocation) throws Throwable;Object plugin(Object target);void setProperties(Properties properties);&#125; 我们可以看到在该接口中一共定义有三个方法，intercept、plugin和setProperties。plugin方法是拦截器用于封装目标对象的，通过该方法我们可以返回目标对象本身，也可以返回一个它的代理。当返回的是代理的时候我们可以对其中的方法进行拦截来调用intercept方法，当然也可以调用其他方法，这点将在后文讲解。setProperties方法是用于在Mybatis配置文件中指定一些属性的。 定义自己的Interceptor最重要的是要实现plugin方法和intercept方法，在plugin方法中我们可以决定是否要进行拦截进而决定要返回一个什么样的目标对象。而intercept方法就是要进行拦截的时候要执行的方法。 对于plugin方法而言，其实Mybatis已经为我们提供了一个实现。Mybatis中有一个叫做Plugin的类，里面有一个静态方法wrap(Object target,Interceptor interceptor)，通过该方法可以决定要返回的对象是目标对象还是对应的代理。 Plugin的wrap方法，它根据当前的Interceptor上面的注解定义哪些接口需要拦截，然后判断当前目标对象是否有实现对应需要拦截的接口，如果没有则返回目标对象本身，如果有则返回一个代理对象。而这个代理对象的InvocationHandler正是一个Plugin。所以当目标对象在执行接口方法时，如果是通过代理对象执行的，则会调用对应InvocationHandler的invoke方法，也就是Plugin的invoke方法。invoke方法的逻辑是：如果当前执行的方法是定义好的需要拦截的方法，则把目标对象、要执行的方法以及方法参数封装成一个Invocation对象，再把封装好的Invocation作为参数传递给当前拦截器的intercept方法。如果不需要拦截，则直接调用当前的方法。Invocation中定义了定义了一个proceed方法，其逻辑就是调用当前方法，所以如果在intercept中需要继续调用当前方法的话可以调用invocation的procced方法。 实现自己的Interceptor而言有两个很重要的注解，一个是@Intercepts，其值是一个@Signature数组。@Intercepts用于表明当前的对象是一个Interceptor，而@Signature则表明要拦截的接口、方法以及对应的参数类型。 使用PageHelper插件进行分页其实我看来也是对我们的sql的拦截，然后进行代理增强生成分页之后的sql具体使用及学习参见PageHelper工作原理 RowBounds分页数据量小时，RowBounds不失为一种好办法。但是数据量大时，实现拦截器就很有必要了。 mybatis 接口加入RowBounds参数service1234@Override@Transactional(isolation = Isolation.READ_COMMITTED, propagation = Propagation.SUPPORTS)public List&lt;RoleBean&gt; queryRolesByPage(String roleName, int start, int limit) &#123; return roleDao.queryRolesByPage(roleName, new RowBounds(start, limit));&#125;]]></content>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Spring】Spring注解整体解析]]></title>
    <url>%2F2019%2F04%2F16%2FSpring%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2Fspringboot%2F</url>
    <content type="text"><![CDATA[Spring Boot的四大神器 auto-configuration 自动配置 starter pom更易管理，减少手动添加依赖项的数量 cli 通过命令行添加参数，运行groovy actuator 应用系统的监控和管理的集成功能，可以查看应用配置的详细信息，例如自动化配置信息、创建的Spring beans信息、系统环境变量的配置信以及Web请求的详细信息等 SpringBoot的注解基础注解 @Configuration 声明该类为配置类，可包含多个@Bean的方法，进行Bean的定义，初始化容器 @Component 可以注解其他类的注解，如@Controller @Service @Repository，当类不好归类时使用 @Bean 放在方法上面，产生一个Bean，交给Spring @Autowired 自动导入依赖的Bean，默认为byType。 @Import 通过导入的方式实现把实例加入到SpringIOC容器中，可以将没有被Spring管理的类导入到Spring容器中 @ImportResource 与Import基本一致，区别导入的是配置文件 @Conditional 通过代码设置的不同条件装在不同的bean @ComponentScan 进行包扫描 @Qualifier：当有多个同一类型的Bean时，可以用@Qualifier(“name”)来指定。与@Autowired配合使用。 @Resource(name=”name”,type=”type”)：没有括号内容的话，默认byName，匹配不到使用byType。 核心注解 @SpringBootApplication，实际主要为@SpringBootConfiguration，@EnableAutoConfiguration，@ComponentScan三个注解的组合 @SpringBootConfiguration 表明此类是一个SpringBoot的配置类@EnableAutoConfiguration 告诉SpringBoot开启自动配置功能；这样自动配置才能生效；@ComponentScan 扫描包 @Conditional @ConditionalOnBean(A.class) 仅在当前上下文中存在A对象时，才会实例化一个Bean@ConditionalOnMissingBean 和上一个相反，不存在时，实例化@ConditionalOnClass 可以仅当某些类存在于classpath上时候才创建某个Bean@ConditionalOnMissingClass 和上面相反，当classpath中没有指定的 Class才开启配置@ConditionalOnProperty 当指定的属性有指定的值时才开启配置。具体操作是通过其两个属性name以及havingValue来实现的，其中name用来从application.properties中读取某个属性值，如果该值为空，则返回false;如果值不为空，则将该值与havingValue指定的值进行比较，如果一样则返回true;否则返回false。如果返回值为false，则该configuration不生效；为true则生效。@ConditionalOnExpression 当SpEL表达式为true时开启配置@ConditionalOnJava 当运行的Java JVM在指定版本范围才开启配置@ConditionalOnResource 当类路径下有指定资源时开启配置@ConditionalOnJndi 当指定JNDI存在时开启配置@ConditionalOnPlatform 当指定的云平台激活时开启配置@ConditionalOnSingleCandidate 当指定的class在容器中只有一个Bean，或者有多个但是为@Primary首选时开启配置 @ConfigurationProperties 将自定义的properties文件映射到实体Bean中 @EnableConfigurationProperties 当@EnableConfigurationProperties注解应用到你的@Configuration时，任何被@ConfigurationProperties注解的beans将自动被Environment属性配置 @AutoConfigureAfter ，在自动配置类上，表明该自动配置类需要在另外指定的自动配置类配置完成时执行。如Mybatis自动配置需要在数据源自动配置类完成之后 @AutoConfigureBefore 与上相反 @AutoConfigureOrder 指定配置类的加载优先级 SpringMVC注解@Controller层主要注解 @RequestMapping属性：value：用于指定请求的 URL。它和 path 属性的作用是一样的。method：用于指定请求的方式。params：用于指定限制请求参数的条件。它支持简单的表达式。要求请求参数的 key 和 value 必须和配置的一模一样。例如：params = {“accountName”}，表示请求参数必须有 accountNameparams = {“moeny!100”}，表示请求参数中 money 不能是 100。headers：用于指定限制请求消息头的条件。 @RequestParam作用：把请求中指定名称的参数给控制器中的形参赋值。属性：value：请求参数中的名称。required：请求参数中是否必须提供此参数。默认值：true。表示必须提供，如果不提供将报错。 @RequestBody作用：用于获取请求体内容。直接使用得到是 key=value&amp;key=value…结构的数据。get 请求方式不适用。属性：required：是否必须有请求体。默认值是:true。当取值为 true 时,get 请求方式会报错。如果取值为 false，get 请求得到是 null。 @ResponseBody作用：该注解用于将Controller的方法返回的对象，通过适当的HttpMessageConverter转换为指定格式后，写入到Response对象的body数据区。 @PathVariable作用：用于绑定 url 中的占位符。例如：请求 url 中 /delete/{id}，这个{id}就是 url 占位符。url 支持占位符是 spring3.0 之后加入的。是 springmvc 支持 rest 风格 URL 的一个重要标志。属性：value：用于指定 url 中占位符名称。required：是否必须提供占位符。 @CookieValue作用：用于把指定 cookie 名称的值传入控制器方法参数。属性：value：指定 cookie 的名称。required：是否必须有此 cookie。 @ModelAttribute作用：该注解是 SpringMVC4.3 版本以后新加入的。它可以用于修饰方法和参数。出现在方法上，表示当前方法会在控制器的方法执行之前，先执行。它可以修饰没有返回值的方法，也可以修饰有具体返回值的方法。出现在参数上，获取指定的数据给参数赋值。属性：value：用于获取数据的 key。key 可以是 POJO 的属性名称，也可以是 map 结构的 key。应用场景：当表单提交数据不是完整的实体类数据时，保证没有提交数据的字段使用数据库对象原来的数据。例如：我们在编辑一个用户时，用户有一个创建信息字段，该字段的值是不允许被修改的。在提交表单数据是肯定没有此字段的内容，一旦更新会把该字段内容置为 null，此时就可以使用此注解解决问题。 @SessionAttribute作用：用于多次执行控制器方法间的参数共享。属性：value：用于指定存入的属性名称type：用于指定存入的数据类型。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】并发容器ConcurrentHashMap、ConcurrentLinkedQueue、ConcurrentSkipListMap]]></title>
    <url>%2F2019%2F03%2F23%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FJava%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[ConcurrentHashMapHashMap线程不安全，多线程put可能会产生死循环HashTable，Collections.synchronizedMap(hashMap)，通过synchronized进行加锁，独占式，一个线程读其他线程必须等待，效率低ConcurrentHashMap，使用CAS和synchronized进行并发安全，底层使用hash表(数组+链表)+红黑树存储，不允许key和value为null 主要属性默认初始值：16，private static final int DEFAULT_CAPACITY = 16;每次扩容2的n次幂冲突链表转红黑树阈值：大于等于8，static final int TREEIFY_THRESHOLD = 8;红黑树转链表阀值，小于等于6（tranfer时，lc、hc=0两个计数器分别++记录原bin、新binTreeNode数量，&lt;=UNTREEIFY_THRESHOLD 则untreeify(lo)）static final int UNTREEIFY_THRESHOLD = 6;扩容阈值：max*0.75，超过当前容量的0.75触发扩容 put方法首先根据hash值计算要插入table的位置，如果位置为空则直接插入，否则插入到链表或者树中详细流程： 判空；ConcurrentHashMap的key、value都不允许为null 计算hash。利用方法计算hash值。static final int spread(int h) {return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;//高16位和低16位进行异或后，在与HASH_BITS进行逻辑与操作 } 遍历table，进行节点插入操作，过程如下： 如果table为空，则表示ConcurrentHashMap还没有初始化，则进行初始化操作：initTable()根据hash值获取节点的位置i，若该位置为空，则直接插入，这个过程是不需要加锁的。计算f 位置：i=(n - 1) &amp; hash如果检测到fh = f.hash == -1，则f是ForwardingNode节点，表示有其他线程正在进行扩容操 作，则帮助线程一起进行扩容操作如果f.hash &gt;= 0 表示是链表结构，则遍历链表，如果存在当前key节点则替换value，否则插入 到链表尾部。如果f是TreeBin类型节点，则按照红黑树的方法更新或者增加节点若链表长度 &gt; TREEIFY_THRESHOLD(默认是8)，则将链表转换为红黑树结构 调用addCount方法，ConcurrentHashMap的size + 1 扩容过程单线程流程： 为每个内核分任务，并保证其不小于16 检查nextTable是否为null，如果是，则初始化nextTable，使其容量为table的两倍 死循环遍历节点，知道finished：节点从table复制到nextTable中，支持并发，请思路如下： 如果节点 f 为null，则插入ForwardingNode（采用Unsafe.compareAndSwapObjectf方法实现），这个是触发并发扩容的关键 如果f为链表的头节点（fh &gt;= 0）,则先构造一个反序链表，然后把他们分别放在nextTable的i和i + n位置，并将ForwardingNode 插入原节点位置，代表已经处理过了 如果f为TreeBin节点，同样也是构造一个反序 ，同时需要判断是否需要进行unTreeify()操作，并把处理的结果分别插入到nextTable的i 和i+n位置，并插入ForwardingNode 节点 所有节点复制完成后，则将table指向nextTable，同时更新sizeCtl = nextTable的0.75倍，完成扩容过程 多线程环境下，ConcurrentHashMap用两点来保证正确性：ForwardingNode和synchronized。当一个线程遍历到的节点如果是ForwardingNode，则继续往后遍历，如果不是，则将该节点加锁，防止其他线程进入，完成后设置ForwardingNode节点，其他线程看到该节点已经处理过了，就遍历下一个节点，如此交叉进行，高效而又安全。 JDK1.8的实现降低锁的粒度，JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（首节点） JDK1.8版本的数据结构变得更加简单，使得操作也更加清晰流畅，因为已经使用synchronized来进行同步，所以不需要分段锁的概念，也就不需要Segment这种数据结构了，由于粒度的降低，实现的复杂度也增加了 JDK1.8使用红黑树来优化链表，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表，这样形成一个最佳拍档 JDK1.8为什么使用内置锁synchronized来代替重入锁ReentrantLock，我觉得有以下几点 因为粒度降低了，在相对而言的低粒度加锁方式，synchronized并不比ReentrantLock差，在粗粒度加锁中ReentrantLock可能通过Condition来控制各个低粒度的边界，更加的灵活，而在低粒度中，Condition的优势就没有了 JVM的开发团队从来都没有放弃synchronized，而且基于JVM的synchronized优化空间更大，使用内嵌的关键字比使用API更加自然 在大量的数据操作下，对于JVM的内存压力，基于API的ReentrantLock会开销更多的内存，虽然不是瓶颈，但是也是一个选择依据 ConcurrentSkipListMap内部主要采用跳表skipList数据结构实现，链表结构主要包含：Node，Index，HeadIndex。Node为最底层的链表节点，Index表示基于Node的索引层，HeadIndex表示索引的层级不支持key或value为null插入查找效率为O(log(n))put方法 首先通过findPredecessor()方法找到父亲节点Node 根据返回的父亲节点以及key-value，新建Node节点，同时通过CAS设置next 设置节点Node，再设置索引节点。采取抛硬币方式决定层次(通过ThreadLocalRandom生成随机数，判断该数与最大层次的大小)，如果大于现存的最大层次，则新增一层，然后新建一个Item链表。否则在相应层次或者小于该数的层次上新增节点。 最后，将新建的Item链表插入到SkipList结构中。 get：获取节点remove：删除节点 ConcurrentSkipListSet内部还是使用ConcurrentSkipListMap，通过Map的key来存储数据保证唯一性，包含一个ConcurrentNavigableMap对象m，而m对象实际上是ConcurrentNavigableMap的实现类ConcurrentSkipListMap的实例 ConcurrentLinkedQueue采用CAS进行实现，可能会产生head和tail更新滞后(head和tail不总指向第一个元素和最后一个元素) 单向链表，当一个线程A入队，必须获取tail节点，此时另一个线程B也要入队，此时tail节点还没有发生变化，tail更新滞后，线程B会插入失败，然后将线程A新插入的节点改为tail节点，但是在自旋死循环里，下一次会插入成功出队时类似 主要方法：offer()：入队poll(): 出队 ConcurrentLinkedDeque对ConcurrentLinkedQueue增强，双向链表 CopyOnWriteArrayList通过数组实现，线程安全的ArrayList，通过ReentrantLock保证线程安全每次对数组进行修改时，都复制一份新数组进行修改，修改之后再替换老数组写操作阻塞，读操作不阻塞 CopyOnWriteArraySet内部使用CopyOnWriteArrayList，通过addIfAbsent()方法来保证元素不重复 参考链接Java并发编程艺术 方腾飞Java并发编程实战 Brian Goetz / Tim Peierls / Joshua Bloch / Joseph Bowbeer / David Holmes / Doug Lea死磕Java并发容器ConcurrentHashMap源码分析（JDK8版本）]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】深入理解各种锁、synchronized、CAS]]></title>
    <url>%2F2019%2F03%2F16%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FJava-%E9%94%81%2F</url>
    <content type="text"><![CDATA[本文主要介绍了锁的基本概念，synchronized，CAS，ReentrantLock，ReentrantReadWriteLock和Condition。 锁的基本概念 公平锁：先到的线程先得到这个锁 非公平锁：若释放锁的时候没有新线程进入，非公平锁等于公平锁，若释放锁的时候有新线程进入，新线程优先执行，为非公平锁 排他锁(独占锁)：在同一时刻仅有一个线程可以进行访问 共享锁：同一时刻能够被多个线程同时持有 可重入锁： 一个线程可以多次访问 自旋锁：让线程等待一段时间，不会挂起。JDK1.6默认为10次。减少了线程切换带来的开销，占用了处理器的时间 自适应自旋锁：自旋的次数不是固定的，由上一次在同一个锁上的自旋时间及锁拥有者的状态决定。如果自旋成功了，下次自旋次数会增加，反之减少。 锁消除：JVM检测到不存在共享数据竞争，对同步锁进行消除。 锁粗化：将多个连续的加锁、解锁操作扩展成一个范围更大的锁。若锁之间比较独立还是需要尽可能细化，尽量在共享数据实际作用时同步。 偏向锁：在无多线程竞争的情况下，尽量减少不必要的轻量级锁执行路径（减少CAS操作，性能开销，上下文切换）。 轻量级锁：在激烈的多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。若有激烈的多线程并发竞争，轻量级锁更慢。 重量级锁：通过对象内部的监视器(monitor)实现，本质是依赖于底层操作系统Mutex lock实现，操作系统进行用户态和内核态切换，成本非常高。 synchronized用的锁存储在Java对象头中，包括两部分：Mark Word(标记字段)和Klass Pointer(类型指针)。类型指针来确定对象是哪个类的实例。标记字段来存储自身运行时的数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等等，主要来控制synchronized的膨胀。 一个类中有同步方法A和普通方法B，两个线程如果有该对象的同一实例那么他们就不能同时执行同步方法A，如果两个线程拥有该对象的不同实例，就可以同时执行同步方法A 同步普通方法，在方法声明中加入synchronized关键字（对象锁）。同一时刻对于每一个类实例，至多只有一个处于可执行状态，避免类成员变量的访问冲突 同步方法块，修饰代码块。锁为括号里面的对象（对象锁）。线程进入synchronized方法的时候获取该对象的锁，当然如果已经有线程获取了这个对象的锁，那么当前线程会等待；synchronized方法正常返回或者抛异常而终止，JVM会自动释放对象锁。 同步静态方法，修饰静态的方法或代码块（类锁）。由于一个class不论被实例化多少次，其中的静态方法和静态变量在内存中都只有一份。所以，一旦一个静态的方法被申明为synchronized，此类所有的实例化对象在调用此方法，共用同一把锁，我们称之为类锁。类锁是概念上的，不是真实存在，因为它其实就是特殊的对象锁，但是static方法被类的所有对象共用。若是实例对象被锁，则实例对象的所有同步方法被锁若是类对象被锁，则类对象的所有同步方法被锁 synchronized锁膨胀过程：synchronized 同步锁一共具有四种状态：无锁、偏向锁、轻量级锁、重量级锁，他们会随着竞争情况逐渐升级，此过程为不可逆。所以 synchronized 锁膨胀过程其实就是无锁 → 偏向锁 → 轻量级锁 → 重量级锁的一个过程 CAS（CompareAndSwap）比较并交换，CAS中有三个参数：内存值V、旧的预期值A、要更新的值B，当且仅当内存值V的值等于旧的预期值A时才会将内存值V的值修改为B，否则什么都不干。 存在问题： 循环时间太长，如果CAS长时间不成功，会给CPU带来非常大开销 只能保证一个共享变量的原子操作。解决：多个变量需要进行封装 ABA问题，原来为A，改为B，又改为A。看似没有改变，实际发生了改变。解决：使用一个版本标识(时间戳)。 CAS和synchronized效率分析 1、对于资源竞争较少的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。2、对于资源竞争严重的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。PS. synchronized在jdk1.6之后，已经改进优化。synchronized的底层实现主要依靠Lock-Free的队列，基本思路是自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。 synchronized和Lock synchronized是Java内置关键字；Lock是一个接口，必须放在try-catch里面，一般在finally里面进行锁的释放synchronized在发生异常时会自动释放线程占有的锁，不会导致死锁；Lock必须要自己进行unLock进行锁的释放synchronized不能够被中断，等待的线程会一直等待；Lock可以使用interrupt进行中断synchronized不保证公平性；Lock可以实现公平锁，在竞争资源激烈情况下，Lock要更好 ReentrantLock ReentrantLock(重入锁)，一种递归无阻塞的同步机制，可选择公平锁还是非公平锁（默认非公平），更强大的锁机制，可减少死锁发生 syncronized和ReentrantLock 与synchronized相比，ReentrantLock提供了更多，更加全面的功能，具备更强的扩展性。例如：时间锁等候，可中断锁等候，锁投票。 ReentrantLock还提供了条件Condition，对线程的等待、唤醒操作更加详细和灵活，所以在多个条件变量和高度竞争锁的地方，ReentrantLock更加适合（以后会阐述Condition）。 ReentrantLock提供了可轮询的锁请求。它会尝试着去获取锁，如果成功则继续，否则可以等到下次运行时处理，而synchronized则一旦进入锁请求要么成功要么阻塞，所以相比synchronized而言，ReentrantLock会不容易产生死锁些。 ReentrantLock支持更加灵活的同步代码块，但是使用synchronized时，只能在同一个synchronized块结构中获取和释放。注：ReentrantLock的锁释放一定要在finally中处理，否则可能会产生严重的后果。 ReentrantLock支持中断处理，且性能较synchronized会好些。 ReentrantReadWriteLock 通过分离读锁和写锁，提高并发量。公平性：支持公平性和非公平性。重入性：支持重入。读写锁最多支持65535个递归写入锁和65535个递归读取锁。锁降级：遵循获取写锁、获取读锁在释放写锁的次序，写锁能够降级成为读锁读锁是一个共享锁，在同一时间可以允许多个读线程同时访问，但是在写线程访问时，所有读线程和写线程都会被阻塞。写锁是一个支持重入的排它锁 Condition 广义上的一种条件队列，为线程提供更为灵活的等待通知模式，线程在调用await()方法挂起，知道线程等待某个条件为真时被signal()唤醒。必须要配合锁一起使用，因为对共享状态变量访问发生在多线程环境，一般为Lock的内部newCondition()实现。 参考链接： Java并发编程艺术 方腾飞Java并发编程实战 Brian Goetz / Tim Peierls / Joshua Bloch / Joseph Bowbeer / David Holmes / Doug Lea深入详解Synchronized同步锁的底层实现Java对象锁和类锁全面解析（多线程synchronized关键字）Java中Synchronized的用法synchronized的锁膨胀过程偏向锁，轻量级锁与重量级锁为什么会相互膨胀?J.U.C之重入锁J.U.C之读写锁J.U.C之Condition]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello Hexo]]></title>
    <url>%2F2018%2F03%2F23%2FHello-Hexo%2F</url>
    <content type="text"><![CDATA[This is my first test on githubBlog by hexo.]]></content>
  </entry>
</search>
