<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【Java】volatile关键字解析]]></title>
    <url>%2F2019%2F10%2F15%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2Fvolatile%2F</url>
    <content type="text"><![CDATA[volatile只能保证多线程中的可见性和有序性，不能保证原子性。volatile关键字是否能保证线程安全？（）答案：不能解析：volatile关键字用在多线程同步中可保证读取的可见性（并发编程中当多个线程访问同一个变量时，一个线程对变量进行了修改，其他线程能够立马看到修改之后的值），1.当某个线程对该变量修改后，会立即将修改后的新值刷回主存，保证主存中永远都是最新的数据2.对该比变量施加了缓存行一致协议。也就是说，当前线程对该变量进行修改后，系统会通知其他线程它们工作缓存中数据已经无效，那么其他线程要再次读取该变量时，就会重新从主存中读取该变量，然后复制一份在它的工作缓存中。JVM只是保证从主内存加载到线程工作内存的值是最新的读取值，而非cache中。 可保证有序性(程序按照代码的先后顺序进行执行)能够禁止指令进行重排序，保证有序性volatile关键字禁止指令重排序有两层意思：1）当程序执行到volatile变量的读操作或者写操作时，在其前面作的操的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。 保证不了原子性问题(一个或多个操作，要么全部执行且不可被打断，要么都不执行)可保证单一操作的原子性，不能保证复合操作的原子性PS . 在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）即这些操作是不可被中断的，要么执行，要么不执行。 i++执行了多部操作,从变量i中读取读取i的值-&gt;值+1 -&gt;将+1后的值写回i中，不能保证原子性和线程安全 在修饰数组时只是修饰指向数组的这个引用，而不是数组的内容，内容修改对其它线程不可见主要的功能是保护变量不被主函数和中断函数反复修改造成读写错误。但多个线程对volatile的写操作，无法保证线程安全。例如假如线程1，线程2 在进行read,load 操作中，发现主内存中count的值都是5，那么都会加载这个最新的值，在线程1堆count进行修改之后，会write到主内存中，主内存中的count变量就会变为6；线程2由于已经进行read,load操作，在进行运算之后，也会更新主内存count的变量值为6；导致两个线程即使用volatile关键字修改之后，还是会存在并发的情况。 参考链接：Java并发编程：volatile关键字解析死磕Java并发-深入理解volatile]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Redis】内存淘汰机制、缓存问题及解决、持久化方案]]></title>
    <url>%2F2019%2F10%2F15%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fredis-study1%2F</url>
    <content type="text"><![CDATA[Redis性能好，对一些结果变化不频繁的结果，存入缓存，加快请求响应高并发进行削峰，减少同一时间对数据库的请求数量，防止数据库崩溃 Redis的常用基本数据类型 (一)String这个其实没啥好说的，最常规的set/get操作，value可以是String也可以是数字。一般做一些复杂的计数功能的缓存。(二)hash这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。博主在做单点登录的时候，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。(三)list使用List的数据结构，可以做简单的消息队列的功能。另外还有一个就是，可以利用lrange命令，做基于redis的分页功能，性能极佳，用户体验好。(四)set因为set堆放的是一堆不重复值的集合。所以可以做全局去重的功能。为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。(五)sorted setsorted set多了一个权重参数score,集合中的元素能够按score进行排列。可以做排行榜应用，取TOP N操作、可以用来做延时任务、可以做范围查找。 Redis的RESP协议规范 均已\r\n结尾 简单字符串 Simple Strings, 以 “+”加号 开头 错误 Errors, 以”-“减号 开头 整数型Integer，以”:”冒号开头 多行字符串，以”$”美元符号开头 数组Arrays，以”*”星号开头 单线程Redis为何这么快 纯内存操作 单线程，避免了频繁的上下文切换，不用考虑各种锁 使用了非阻塞IO多路复用，同一个线程同时处理多个请求 Redis的过期策略和内存淘汰机制，及内存不足的处理办法 比如你redis只能存5G数据，可是你写了10G，那会删5G的数据。怎么删的，这个问题思考过么？还有，你的数据已经设置了过期时间，但是时间到了，内存占用率还是比较高，有思考过原因么?回答:内存不足的处理办法： 增加内存 对内存设置淘汰策略 使用redis集群 redis采用的是定期删除+惰性删除策略。为什么不用定时删除策略?定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略.定期删除+惰性删除是如何工作的呢?定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。采用定期删除+惰性删除就没其他问题了么?不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制。在redis.conf中有一行配置` maxmemory-policy volatile-lru该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己)1）noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。应该没人用吧。2）allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。推荐使用，目前项目在用这种。3）allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。应该也没人用吧，你不删最少使用Key,去随机删。4）volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。这种情况一般是把redis既当缓存，又做持久化存储的时候才用。不推荐5）volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。依然不推荐6）volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。不推荐ps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。 使用缓存的缺点 缓存和数据库双写一致性问题 缓存雪崩问题 缓存穿透问题 缓存并发竞争问题 缓存一致性问题 一致性分为最终一致性（通俗来说就是最后结果相同）和强一致性(每时每刻都是相同的)。数据库和缓存进行双写，必然会存在不一致的问题，只能降低不一致，不能完全避免。有强一致性要求的不能使用缓存。一般采用先更新数据库，再删除缓存失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。命中：应用程序从cache中取数据，取到后返回。更新：先把数据存到数据库中，成功后，再让缓存失效。 缓存雪崩问题 缓存雪崩，即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。解决方案: 给缓存的失效时间，加上一个随机值，避免集体失效。 使用互斥锁，但是该方案吞吐量明显下降了。 双缓存。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点 I 从缓存A读数据库，有则直接返回II A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。III 更新线程同时更新缓存A和缓存B。 缓存穿透问题 缓存j穿透，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。解决方案: 利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试 采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。 提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。适用于大用户集，实时性要求较低的场景，如有几亿的数据集，每隔一段时间会新增用户进去，在更新之前新用户的访问会存在缓存穿透问题。 Redis缓存并发竞争 基于zookeeper实现分布式锁，每个通过zookeeper获取分布式锁，确保同一时间，只有一个实例在操作某个key。当进行写之前，判断当前的value时间戳是否比缓存里面的时间戳新，若是则写，否则，不能使用旧数据覆盖新数据。 redis 的 setnx 实现内置的锁：要设置超时时间，防止抢占到锁的客户端因失败、崩溃或其他原因没有办法释放锁而造成死锁 利用redis自带的incr命令,decr命令 使用乐观锁的方式进行解决，通过watch进行监控，后面的事务有条件执行，如果在watch的exec执行时，watch的key对应的value改变了，事务不进行执行，但是不推荐使用redis的事务机制。因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。 Redis持久化方案 RDB在指定的时间间隔能对你的数据进行快照存储. AOF使用日志记录所有的写操作，在服务器启动时，通过执行这些命令还原数据库。AOF的持久化更加完整，安全，默认每秒钟fsync一次，出现故障时可使用redis-check-aof进行问题修复，并且自己可以对aof文件进行重写RDB可能会丢失数据，但是体积更小，保存某个时间点的所有数据，进行大数据集恢复时速度要快一般两种方式同时使用，在同时使用时，优先使用AOF进行数据集的恢复 参考链接分布式之redis复习精讲主从DB与cache一致性Redis协议规范（译文）Redis官方持久化Redis使用中存在的问题缓存更新套路]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【MySQL】索引，锁，InnoDB特点]]></title>
    <url>%2F2019%2F10%2F10%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMySQL%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[索引InnoDB默认索引B+树，自适应hash索引（自动创建）除了叶子节点，其他都是索引字段，叶子节点存储真实数据密集索引 ：一个索引项(1001)对应一个数据记录(1001) 稀疏索引 ： 一个索引项(1001)对应一块数据记录(1001,1002,1003) 聚集索引 ： 索引的逻辑顺序和磁盘行物理位置（数据存储位置）顺序相同(一般为主键索引，一个表只有一个，整个表成为一个索引，如果表中没有显示指定主键，则会选择表中的第一个不允许为NULL的唯一索引，如果还是没有的话，就采用Innodb存储引擎为每行数据内置的6字节ROWID作为聚集索引) 非聚集索引 ： 索引的逻辑顺序和磁盘行的物理位置（数据）顺序不同(普通，唯一，全文，每个索引互相独立，给字段创建一个索引，字段中的数据就会被复制一份，生成该字段索引，查找的时候先通过该索引找到对应的主键索引，然后再通过主键索引找到对应的值) 为什么在插入时非聚集索引要更快一些，聚集索引需要先找到位置后再进行插入 覆盖(复合)索引，多个字段组成的索引，若查询时是查找这些字段的值，则不需要使用主键索引 索引使用注意 尽量选择字段长度比较小，重复比较少的字段建立 避免在where语句后果进行null值判断，null会使索引失效 避免使用!=和&lt;&gt;，not , not in, not like, !&gt;,!&lt;，单一索引失效，复合索引还有效 避免使用or进行连接条件，如果一个有索引一个没有索引将使索引失效 前导模糊查询”%%”，”%abc”索引失效，”ab%”索引有效 不要在where里面对字段进行计算 复合索引最常用的放最左边 对经常进行删除，修改，插入的表尽量少建立索引 — 找到不到笔记了，后续再加 数据库事务① Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。② Repeatable read (可重复读)：可避免脏读、不可重复读的发生。③ Read committed (读已提交)：可避免脏读的发生。④ Read uncommitted (读未提交)：最低级别，任何情况都无法保证。 脏读 ：表示一个事务能够读取另一个事务中还未提交的数据。比如，某个事务尝试插入记录 A，此时该事务还未提交，然后另一个事务尝试读取到了记录 A。 不可重复读 ：是指在一个事务内，多次读同一数据。 幻读 ：指同一个事务内多次查询返回的结果集不一样。比如同一个事务 A 第一次查询时候有 n 条记录，但是第二次同等条件下查询却有 n+1 条记录，这就好像产生了幻觉。发生幻读的原因也是另外一个事务新增或者删除或者修改了第一个事务结果集里面的数据，同一个记录的数据内容被修改了，所有数据行的记录就变多或者变少了。 锁InnoDB支持行锁和表锁，MyISAM支持表锁表级锁：开销小，加锁快，不会出现死锁。锁定粒度大，发生锁冲突的概率最高，并发量最低。行级锁：开销大，加锁慢，会出现死锁。锁力度小，发生锁冲突的概率小，并发度最高。 乐观锁：每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在提交更新的时候会判断一下在此期间别人有没有去更新这个数据。 悲观锁：每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻止，直到这个锁被释放。 InnoDB特点自适应hash索引会监控对二级索引的查找，如果发现某一个二级索引被频繁访问，二级索引就成为一个热数据。 经常访问的二级索引数据会自动被生成到Hash索引里面去，自适应哈希索引通过缓冲池的B+树构造。不是整个表都建立索引，是对某些页建立索引 限制： 只能使用等值比较 会占用缓冲池 无法用于排序 有冲突可能 人为无法干预 两次写（提高可靠性）：问题点：部分写失效，当数据正在从内存向磁盘中写一个数据页时，数据库宕机，导致只写入了部分数据，部分数据丢失。页本身已经损坏，重做日志无效，重做日志是对页的物理修改。， 解决方案：两次写 添加 内存两次写缓冲 2MB 磁盘共享表空间连续128页 2MB 原理 刷新缓冲池脏页，不直接写数据文件，先拷贝至内存中的两次写缓冲区 接着从两次写缓冲区分两次写入磁盘共享表空间的物理磁盘中，每次写入1MB，然后马上调用fsync函数，同步磁盘，避免缓冲写带来的问题 第二步完成后，将两次写缓冲区的页离散的写入到数据文件中 这样就可以解决上文提到的部分写失效的问题，因为在磁盘共享表空间中已有数据页副本拷贝，如果数据库在页写入数据文件的过程中宕机，在实例恢复时，可以从共享表空间中找到该页副本，将其拷贝覆盖原有的数据页，再应用重做日志即可。 插入缓冲机制(提高写性能)问题：涉及辅助索引的插入效率低 解决方案： 对于非聚集类索引的插入和更新操作，不是每一次都直接插入到索引页中，而是先插入到内存中。如果索引页在缓冲池中，就直接插入，如果不在缓冲池中，就先将其躺入插入缓冲池中，然后以一定的频率和索引页合并，将同一个索引页中的锁哥插入合并到一个IO操作中。 插入缓冲的问题 数据库宕机的之后，恢复时间变长 写密集情况下 ，插入缓冲会占用过多的缓冲池内存 InnoDB和MyIASM区别InnoDB支持行锁和表锁，外键，数据缓存， 事务，不支持全文检索，锁的粒度小，适合并发度高的情况，使用聚簇索引，更适合范围查找和排序 MyIASM支持表锁，全文检索，不支持事务，外键，在写操作是会锁定整张表，使用非聚簇索引]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】普通容器，同步容器和并发容器]]></title>
    <url>%2F2019%2F10%2F10%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FJava%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Java容器本文主要对Java中的容器进行介绍，主要分为普通容器，同步容器和并发容器 普通容器 ArrayList：适合读取O(1)，默认初始容量为10，size()是实际元素的个数 12//Default initial capacity.private static final int DEFAULT_CAPACITY = 10; 扩容方式，自动扩容还需要进行一个copy，消耗的资源较多 ，尽可能设置好初始大小 123int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);...elementData = Arrays.copyOf(elementData, newCapacity); LinkedList 适合添加和删除 O(1)，查找O(n) HashMap 实现了Map接口，底层由数组bucket+链表(散列表)+红黑树实现，几种数据结构存的都是键值对，hashcode相同bucket位置来储存Entry对象，当出现hash冲突时使用链表存储entry插入开头，当冲突数大于8时使用红黑树存储，使用链表键值可以为null，初始容量16，当元素数量达到总容量的0.75扩容，扩容方式2的n次方 123//The default initial capacity - MUST be a power of two.static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 遍历删除1234567891011121314151617181920//listIterator&lt;String&gt; it = list.iterator(); while(it.hasNext())&#123; String x = it.next(); if(x.equals("del"))&#123; it.remove(); &#125;&#125;//mapIterator&lt;Map.Entry&lt;Integer, String&gt;&gt; it = map.entrySet().iterator(); while(it.hasNext())&#123; Map.Entry&lt;Integer, String&gt; entry = it.next(); Integer key = entry.getKey(); if(key % 2 == 0)&#123; System.out.println("To delete key " + key); it.remove(); System.out.println("The key " + + key + " was deleted"); &#125; &#125; 同步容器 Vector Stack HashTable 其中都是使用synchronized进行修饰，保证同一个变量只能由一个线程访问 并发容器 ConcurrentHashMap 和Hashmap的存储方式一样，但是通过对数组进行加锁synchronized和使用CAS(Compare And Swap)进行并发控制 CopyOnWriteArrayList - 线程安全的 ArrayList CopyOnWriteArraySet - 线程安全的 Set，它内部包含了一个 CopyOnWriteArrayList，因此本质上是由 CopyOnWriteArrayList 实现 ConcurrentSkipListSet - 相当于线程安全的 TreeSet。它是有序的 Set。它由 ConcurrentSkipListMap 实现。 ConcurrentHashMap - 线程安全的 HashMap。采用分段锁实现高效并发。 ConcurrentSkipListMap - 线程安全的有序 Map。使用跳表实现高效并发。 ConcurrentLinkedQueue - 线程安全的无界队列。底层采用单链表。支持 FIFO。 ConcurrentLinkedDeque - 线程安全的无界双端队列。底层采用双向链表。支持 FIFO 和 FILO。 ArrayBlockingQueue - 数组实现的阻塞队列。 LinkedBlockingQueue - 链表实现的阻塞队列。 LinkedBlockingDeque - 双向链表实现的双端阻塞队列。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】ThreadPool]]></title>
    <url>%2F2019%2F10%2F09%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FThreadPool%2F</url>
    <content type="text"><![CDATA[线程池作用：减少对线程的创建和销毁，方便对线程进行管理好处： 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁进行的资源消耗 提高响应速度。当任务到达时，不用创建新的线程就能直接从线程池取出线程进行执行 提高线程的可管理性。可对线程进行统一分配、调优和监控 ThreadPool的参数 源码如上图 corePoolSize：核心线程数 核心线程会一直存活，即使没有任务需要执行当线程数小于核心线程数时（还未满，就会一直增），即使有线程空闲，线程池也会优先创建新线程处理设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭 maximumPoolSize：最大的线程数 corePoolSize&lt;线程数&lt;maximumPoolSize，且任务队列已满时。线程池会创建新线程来处理任务，直到线程数量达到maximumPoolSize当线程数已经=maximumPoolSize，且任务队列已满时，线程池会拒绝处理任务而抛出异常 keepAliveTime：线程空闲时间 当线程空闲时间达到keepAliveTime时，线程会被销毁，直到线程数量=corePoolSize 如果allowCoreThreadTimeout=true，则会直到线程数量=0（这个特性需要注意） unit：空闲时间单位 BlockingQueue workQueue ：任务队列 当核心线程数达到最大时，新任务会放在队列中排队等待执行 ArrayBlockingQueue：基于数组结构的有界阻塞队列，FIFO。 LinkedBlockingQueue：基于链表结构的有界阻塞队列，FIFO。 SynchronousQueue：不存储元素的阻塞队列，每个插入操作都必须等待一个移出操作，反之亦然。 PriorityBlockingQueue：具有优先界别的阻塞队列。 ThreadFactory threadFactory 创建线程的工厂 RejectedExecutionHandler handler：拒绝策略 两种情况会拒绝处理任务： 1、当线程数已经达到maxPoolSize，且任务队列已满时，会拒绝新任务 2、当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务（并不是立马停止，而是执行完再停止）。 若拒绝后，此时，线程池会调用rejectedExecutionHandler来处理这个任务。如果没有设置，默认值是AbortPolicy，会抛出异常 hreadPoolExecutor类有几个内部实现类来处理这类情况： 1： AbortPolicy 丢弃任务，抛运行时异常 2：CallerRunsPolicy 执行任务（这个策略重试添加当前的任务，他会自动重复调用 execute() 方法，直到成功） 如果执行器已关闭,则丢弃. 3：DiscardPolicy 对拒绝任务直接无声抛弃，没有异常信息 4：DiscardOldestPolicy 对拒绝任务不抛弃，而是抛弃队列里面等待最久的（队列头部的任务将被删除）一个线程，然后把拒绝任务加到队列（Queue是先进先出的任务调度算法，具体策略会咋下面有分析）（如果再次失败，则重复此过程） 5：实现RejectedExecutionHandler接口，可自定义处理器（可以自己实现然后set进去） 线程池的处理流程 如果此时线程池中的数量小于 corePoolSize ，即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。（需获取全局锁） 如果此时线程池中的数量等于 corePoolSize ，但是缓冲队列 workQueue 未满，那么任务被放入缓冲队列。 如果此时线程池中的数量大于 corePoolSize ，缓冲队列 workQueue 满，并且线程池中的数量小于maximumPoolSize ，建新的线程来处理被添加的任务。（需获取全局锁） 如果此时线程池中的数量大于 corePoolSize ，缓冲队列 workQueue 满，并且线程池中的数量等于maximumPoolSize ，那么通过 handler 所指定的策略来处理此任务。 Executor框架提供了三种线程池 Executors.newFixedThreadPool(int); //创建固定容量大小的缓冲池 corePoolSize 和 maximumPoolSize都设置为创建FixedThreadPool时指定的参数nThreads，意味着当线程池满时且阻塞队列也已经满时，如果继续提交任务，则会直接走拒绝策略，该线程池不会再新建线程来执行任务，而是直接走拒绝策略。FixedThreadPool使用的是默认的拒绝策略，即AbortPolicy，则直接抛出异常。 keepAliveTime设置为0L，表示空闲的线程会立刻终止。 workQueue则是使用LinkedBlockingQueue，但是没有设置范围，那么则是最大值（Integer.MAX_VALUE），这基本就相当于一个无界队列了。使用该“无界队列”则会带来哪些影响呢？当线程池中的线程数量等于corePoolSize 时，如果继续提交任务，该任务会被添加到阻塞队列workQueue中，当阻塞队列也满了之后，则线程池会新建线程执行任务直到maximumPoolSize。由于FixedThreadPool使用的是“无界队列”LinkedBlockingQueue，那么maximumPoolSize参数无效，同时指定的拒绝策略AbortPolicy也将无效。而且该线程池也不会拒绝提交的任务，如果客户端提交任务的速度快于任务的执行，那么keepAliveTime也是一个无效参数。 Executors.newSingleThreadExecutor(); //创建容量为1的缓冲池 作为单一worker线程的线程池，SingleThreadExecutor把corePool和maximumPoolSize均被设置为1，和FixedThreadPool一样使用的是无界队列LinkedBlockingQueue,所以带来的影响和FixedThreadPool一样，如果把这个当作全局线程池，可以很好实现异步，并且还能保证任务的顺序执行，进而达到消峰的效果 Executors.newCachedThreadPool(); //创建一个缓冲池，缓冲池容量大小为Integer.MAX_VALUE CachedThreadPool的corePool为0，maximumPoolSize为Integer.MAX_VALUE，这就意味着所有的任务一提交就会加入到阻塞队列中。keepAliveTime这是为60L，unit设置为TimeUnit.SECONDS，意味着空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被终止。阻塞队列采用的SynchronousQueue，而我们在【死磕Java并发】—-J.U.C之阻塞队列：SynchronousQueue中了解到SynchronousQueue是一个没有元素的阻塞队列，加上corePool = 0 ，maximumPoolSize = Integer.MAX_VALUE，这样就会存在一个问题，如果主线程提交任务的速度远远大于CachedThreadPool的处理速度，则CachedThreadPool会不断地创建新线程来执行任务，这样有可能会导致系统耗尽CPU和内存资源，所以在使用该线程池是，一定要注意控制并发的任务数，否则创建大量的线程可能导致严重的性能问题。 ScheduledThreadPoolExecutor 延时和周期的线程池ScheduledThreadPoolExecutor，继承ThreadPoolExecutor且实现了ScheduledExecutorService接口，它就相当于提供了“延迟”和“周期执行”功能的ThreadPoolExecutor。在JDK API中是这样定义它的：ThreadPoolExecutor，它可另行安排在给定的延迟后运行命令，或者定期执行命令。需要多个辅助线程时，或者要求 ThreadPoolExecutor 具有额外的灵活性或功能时，此类要优于 Timer。 一旦启用已延迟的任务就执行它，但是有关何时启用，启用后何时执行则没有任何实时保证。按照提交的先进先出 (FIFO) 顺序来启用那些被安排在同一执行时间的任务。1234567891011121314151617181920212223public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, RejectedExecutionHandler handler)&#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), handler);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler)&#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler);&#125; 参考：https://cloud.tencent.com/developer/article/1497458http://cmsblogs.com/?p=2448]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】ThreadLocal]]></title>
    <url>%2F2019%2F10%2F09%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[作用及基本介绍ThreadLocal解决多线程环境成员变量的冲突问题（解决共享冲突），不是解决线程同步问题，与线程同步机制不同，线程同步是多个线程共享同一个变量（用空间换时间），而ThreadLocal是每一个线程创建一个单独的变量副本，每个线程可以独立的改变自己的变量副本，不影响其他线程 get()：返回此线程局部变量的当前线程副本中的值。initialValue()：返回此线程局部变量的当前线程的“初始值”。remove()：移除此线程局部变量当前线程的值。set(T value)：将此线程局部变量的当前线程副本中的值设置为指定值。 ThreaLocalMapThreadLocal内部还有一个静态内部类ThreadLocalMap，该内部类才是实现线程隔离机制的关键，get()、set()、remove()都是基于该内部类操作。ThreadLocalMap提供了一种用键值对方式存储每一个线程的变量副本的方法，key为当前ThreadLocal对象（实际上是指向该ThreadLocal对象的弱引用），value则是对应线程的变量副本。 对于ThreadLocal需要注意的有两点：ThreadLocal实例本身是不存储值，它只是提供了一个在当前线程中找到副本值得key。是ThreadLocal包含在Thread中，而不是Thread包含在ThreadLocal中。 为什么使用弱引用 因为如果这里使用普通的key-value形式来定义存储结构，实质上就会造成节点的生命周期与线程强绑定，只要线程没有销毁，那么节点在GC分析中一直处于可达状态，没办法被回收，而程序本身也无法判断是否可以清理节点。弱引用是Java中四档引用的第三档，比软引用更加弱一些，如果一个对象没有强引用链可达，那么一般活不过下一次GC。当某个ThreadLocal已经没有强引用可达，则随着它被垃圾回收，在ThreadLocalMap里对应的Entry的键值会失效，这为ThreadLocalMap本身的垃圾清理提供了便利。 ThreadLocalMap 的散列算法 斐波那契散列法，来保证哈希表的离散度。而它选用的乘数值即是2^32 * 黄金分割比。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】Serializable]]></title>
    <url>%2F2019%2F10%2F05%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2FJava-Serializable%2F</url>
    <content type="text"><![CDATA[Java序列化，将Java对象转换为字节数组，便于存储传输 反序列化，将字节数组转换为Java对象 如果一个类能够序列化，他的子类能够序列化 如果子类实现了Serializable接口，父类没有实现，父类不能被序列化，子类可以 由static修饰的类的成员，transient修饰的对象代表对象的临时数据，不能被序列化]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Java】基本类型和包装类型]]></title>
    <url>%2F2019%2F10%2F05%2FJava%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%2F%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%8C%85%E8%A3%85%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[基本类型和包装类型 包装类型可以为null，基本类型不可以，如果数据库查询为null，但是使用基本类型接收，要进行自动拆箱，Integer转为int，抛出空指针异常 包装类型可以用于泛型，基本类型不可以 基本类型存在栈中，包装类型存储的是堆中的引用，基本类型更加高效 两个包装类型的(equals)值可能相同，但是(==)不是同一对象 当需要进行自动装箱时，如果数字在-128到127之间，会直接使用缓存中的对象，而不是重新创建一个对象由基本类型如：int转换为包装类型Integer 自动装箱，Integer.ValueOf()由包装类型如：Integer转为基本类型int 自动装箱，Integer.intValue()]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Spring学习笔记3】Spring动态代理]]></title>
    <url>%2F2019%2F10%2F02%2FSpring%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2Fproxy-study%2F</url>
    <content type="text"><![CDATA[动态代理： 特点：字节码随用随创建，随用随加载 作用：不修改源码的基础上对方法增强 分类： 基于接口的动态代理 基于子类的动态代理 基于子类的动态代理： 涉及的类：Enhancer 提供者：第三方cglib库 如何创建代理对象： 使用Enhancer类中的create方法 创建代理对象的要求： 被代理类不能是最终类 create方法的参数： Class：字节码 它是用于指定被代理对象的字节码。 callback：用于提供增强的代码 它是让我们写如何代理。我们一般都是些一个该接口的实现类，通常情况下都是匿名内部类，但不是必须的。 此接口的实现类都是谁用谁写。 我们一般写的都是该接口的子接口实现类：MethodInterceptor 通过接口实现动态代理123456789101112131415161718192021222324252627IProducer proxyProducer = (IProducer) Proxy.newProxyInstance(producer.getClass().getClassLoader(),producer.getClass().getInterfaces(),new InvocationHandler() &#123; /** * 作用：执行被代理对象的任何接口方法都会经过该方法 * 方法参数的含义 * @param proxy 代理对象的引用 * @param method 当前执行的方法 * @param args 当前执行方法所需的参数 * @return 和被代理对象方法有相同的返回值 * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //提供增强的代码 Object returnValue = null; //1.获取方法执行的参数 Float money = (Float)args[0]; //2.判断当前方法是不是销售 if("saleProduct".equals(method.getName())) &#123; returnValue = method.invoke(producer, money*0.8f); &#125; return returnValue; &#125;&#125;);proxyProducer.saleProduct(10000f); 通过cglib实现动态代理1234567891011121314151617181920212223242526Producer cglibProducer = (Producer)Enhancer.create(producer.getClass(), new MethodInterceptor() &#123; /** * 执行北地阿里对象的任何方法都会经过该方法 * @param proxy * @param method * @param args * 以上三个参数和基于接口的动态代理中invoke方法的参数是一样的 * @param methodProxy ：当前执行方法的代理对象 * @return * @throws Throwable */ @Override public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; //提供增强的代码 Object returnValue = null; //1.获取方法执行的参数 Float money = (Float)args[0]; //2.判断当前方法是不是销售 if("saleProduct".equals(method.getName())) &#123; returnValue = method.invoke(producer, money*0.8f); &#125; return returnValue; &#125;&#125;);cglibProducer.saleProduct(12000f);]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Spring学习笔记2】常用的各种注解及替代xml配置的作用]]></title>
    <url>%2F2019%2F10%2F02%2FSpring%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2FSpring-study2%2F</url>
    <content type="text"><![CDATA[123&lt;bean id="" class="" scope="" init-method="" destroy-method=""&gt; &lt;property name="" value="" | ref=""&gt;&lt;/property&gt; &lt;/bean&gt; 用于创建对象 他们的作用就和在XML配置文件中编写一个标签实现的功能是一样的Component: 作用：用于把当前类对象存入spring容器中 属性： value：用于指定bean的id。当我们不写时，它的默认值是当前类名，且首字母改小写。Controller：一般用在表现层Service：一般用在业务层Repository：一般用在持久层以上三个注解他们的作用和属性与Component是一模一样。他们三个是spring框架为我们提供明确的三层使用的注解，使我们的三层对象更加清晰 用于注入数据 他们的作用就和在xml配置文件中的bean标签中写一个标签的作用是一样的@Autowired: 作用：自动按照类型注入。只要容器中有唯一的一个bean对象类型和要注入的变量类型匹配，就可以注入成功 如果ioc容器中没有任何bean的类型和要注入的变量类型匹配，则报错。 如果Ioc容器中有多个类型匹配时： 出现位置： 可以是变量上，也可以是方法上 细节： 在使用注解注入时，set方法就不是必须的了。@Qualifier: 作用：在按照类中注入的基础之上再按照名称注入。它在给类成员注入时不能单独使用（需要和Autowired一起使用）。但是在给方法参数注入时可以 属性：value：用于指定注入bean的id。 @Resource 作用：直接按照bean的id注入。它可以独立使用属性： name：用于指定bean的id。以上三个注入都只能注入其他bean类型的数据，而基本类型和String类型无法使用上述注解实现。 另外，集合类型的注入只能通过XML来实现。@Value 作用：用于注入基本类型和String类型的数据 属性： value：用于指定数据的值。它可以使用spring中SpEL(也就是spring的el表达式） SpEL的写法：${表达式} 用于改变作用范围 他们的作用就和在bean标签中使用scope属性实现的功能是一样的 @Scope 作用：用于指定bean的作用范围 属性： value：指定范围的取值。常用取值：singleton prototype 和生命周期相关 他们的作用就和在bean标签中使用init-method和destroy-methode的作用是一样的 @PreDestroy 作用：用于指定销毁方法 @PostConstruct 作用：用于指定初始化方法 配置类里面常用的注解 @Configuration 作用：指定当前类是一个配置类 细节：当配置类为AnnotationConfigApplicationContext对象创建的参数时，该注解可以不写。@ComponentScan 作用：用于通过注解指定spring在创建容器时要扫描的包 属性： value：它和basePackages的作用是一样的，都是用于指定创建容器时要扫描的包。 我们使用此注解就等同于在xml中配置了:&lt;context:component-scan base-package=&quot;com.example&quot;&gt;&lt;/context:component-scan&gt;@Bean 作用：用于把当前方法的返回值作为bean对象存入spring的ioc容器中 属性: name:用于指定bean的id。当不写时，默认值是当前方法的名称 细节： 当我们使用注解配置方法时，如果方法有参数，spring框架会去容器中查找有没有可用的bean对象。 查找的方式和Autowired注解的作用是一样的@Import 作用：用于导入其他的配置类 属性： value：用于指定其他配置类的字节码。 当我们使用Import的注解之后，有Import注解的类就父配置类，而导入的都是子配置类@PropertySource 作用：用于指定properties文件的位置 属性： value：指定文件的名称和路径。 关键字：classpath，表示类路径下]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Spring学习笔记1】IOC的创建和Bean的管理]]></title>
    <url>%2F2019%2F10%2F02%2FSpring%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2FSpring-study1%2F</url>
    <content type="text"><![CDATA[Spring 是什么分层的轻量型开源框架，以 IoC（Inverse Of Control：反转控制）和 AOP（Aspect Oriented Programming：面向切面编程）为内核 优势 方便解耦，简化开发通过 Spring提供的 IoC容器，可以将对象间的依赖关系交由 Spring进行控制，避免硬编码所造成的过度程序耦合。用户也不必再为单例模式类、属性文件解析等这些很底层的需求编写代码，可以更专注于上层的应用。 AOP 编程的支持通过 Spring的 AOP 功能，方便进行面向切面的编程，许多不容易用传统OOP 实现的功能可以通过 AOP 轻松应付。 声明式事务的支持可以将我们从单调烦闷的事务管理代码中解脱出来，通过声明式方式灵活的进行事务的管理，提高开发效率和质量。 方便集成各种优秀框架Spring可以降低各种框架的使用难度， 提供了对各种优秀框架 （Struts、 Hibernate、 Hessian、 Quartz等）的直接支持。 IOC控制反转，将主动创建对象的权利交给Spring框架来管理(在当前类需要用到其他类的对象，由Spring创建，只需要在配置文件中声明依赖关系的维护，不用考虑对象是如何创建出来的)目的：降低耦合内部通过工厂模式进行Bean的创建，通过一个Map进行Bean的管理 依赖注入能注入的数据：有三类 基本类型和String其他bean类型（在配置文件中或者注解配置过的bean）复杂类型/集合类型 注入的方式：有三种 第一种：使用构造函数提供第二种：set方法注入第三种：使用接口注入 构造函数注入 使用的标签:constructor-arg标签中的属性type：用于指定要注入的数据的数据类型，该数据类型也是构造函数中某个或某些参数的类型index：用于指定要注入的数据给构造函数中指定索引位置的参数赋值。索引的位置是从0开始name：用于指定给构造函数中指定名称的参数赋值 常用的 =============以上三个用于指定给构造函数中哪个参数赋值value：用于提供基本类型和String类型的数据ref：用于指定其他的bean类型数据。它指的就是在spring的Ioc核心容器中出现过的bean对象优势：在获取bean对象时，注入数据是必须的操作，否则对象无法创建成功。弊端：改变了bean对象的实例化方式，使我们在创建对象时，如果用不到这些数据，也必须提供。1234567 &lt;bean id="" class=""&gt; &lt;constructor-arg name="name" value=""&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="birthday" ref="now"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 配置一个日期对象 --&gt;&lt;bean id="now" class="java.util.Date"&gt;&lt;/bean&gt; Set方法注入 标签：property出现的位置：bean标签的内部标签的属性 name：用于指定注入时所调用的set方法名称 value：用于提供基本类型和String类型的数据 ref：用于指定其他的bean类型数据。它指的就是在spring的Ioc核心容器中出现过的bean对象优势： 创建对象时没有明确的限制，可以直接使用默认构造函数弊端： 如果有某个成员必须有值，则获取对象是有可能set方法没有执行。1234567891011121314&lt;bean id="" class=""&gt;&lt;!--用于给List结构集合注入的标签： list array set用于给Map结构集合注入的标签: map props结构相同，标签可以互换--&gt; &lt;property name="myList"&gt; &lt;array&gt; &lt;value&gt;AAA&lt;/value&gt; &lt;value&gt;BBB&lt;/value&gt; &lt;value&gt;CCC&lt;/value&gt; &lt;/array&gt; &lt;/property&gt;&lt;/bean&gt; 接口注入ApplicationContext的三个常用实现类 ClassPathXmlApplicationContext：它可以加载类路径下的配置文件，要求配置文件必须在类路径 下。不在的话，加载不了。(更常用) FileSystemXmlApplicationContext：它可以加载磁盘任意路径下的配置文件(必须有访问权限） AnnotationConfigApplicationContext：它是用于读取注解创建容器的 ApplicationContext和BeanFactory的区别 BeanFactory： Spring最底层的接口，各种Bean的定义，配置初始化，实例化，控制bean的生命周期 使用延迟加载，读取配置文件时不会创建对象，使用时才会创建 ApplicationContext： BeanFactory的派生，可进行更多的扩展，继承messagesource 支持国际化，统一资源文件访 问，同时加载多个配置文件，载入多个上下文使每个上下文专注特定层次容器启动时，读取配 置文件后一次性创建所有的Bean，有利于发现配置错误，但占用过多的内存空间 区别：BeanFactory 通常以编程方式创建，ApplicationContext 以声明方式创建BeanFactory 延迟加载(创建多例对象使用)，ApplicationContext 立即加载(创建单例对象使用) 都支持BeanPostProcessor、BeanFactoryPostProcess，BeanFactory需要手动注册，applicationContext自动注册 Spring对Bean的管理细节创建Bean的三种方式： 使用默认构造函数创建，在Spring的配置文件中使用bean标签，配以id和class属性之后，且没有其他属性和标签时,采用的就是默认构造函数创建bean对象.此时如果类中没有默认构造函数，则对象无法创建。 1&lt;bean id="" class=""&gt;&lt;/bean&gt; 使用普通工厂中的方法创建对象（使用某个类中的方法创建对象，并存入spring容器） 1&lt;bean id="" factory-bean="" factory-method="" &gt;&lt;/bean&gt; 使用工厂中的静态方法创建对象（使用某个类中的静态方法创建对象，并存入spring容器) 1&lt;bean id="" class="" factory-method="" &gt;&lt;/bean&gt; bean标签的scope属性： 作用：用于指定bean的作用范围 取值： 常用的就是单例的和多例的singleton：单例的（默认值）prototype：多例的request：作用于web应用的请求范围session：作用于web应用的会话范围global-session：作用于集群环境的会话范围（全局会话范围），当不是集群环境时，它就是session bean对象的生命周期单例对象出生：当容器创建时对象出生（解析完配置文件，立即创建）活着：只要容器还在，对象一直活着死亡：容器销毁，对象消亡总结：单例对象的生命周期和容器相同多例对象出生：当我们使用对象时spring框架为我们创建（使用时创建，延迟创建）活着：对象只要是在使用过程中就一直活着。死亡：当对象长时间不用，且没有别的对象引用时，由Java的垃圾回收器回收 AOP将与业务逻辑无关的代码如日志，权限控制分离，减少系统重复代码，降低耦合，便于扩展和维护 基于动态代理，如果代理对象实现了某个接口，则使用JDK的动态代理创建代理对象 如果代理对象没有试下接口的对象，就使用CGlib动态代理生成一个被代理对象的子类作为代理 Spring AOP和AspectJ AOP SpringAOP 运行时增强 AspectJ 编译时增强 基于代理 基于字节码操作 性能一般 性能更好 PS.解耦的思路： 第一步：使用反射来创建对象，而避免使用new关键字。 第二步：通过读取配置文件来获取要创建的对象全限定类名。]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【MySQL】char和varchar的区别]]></title>
    <url>%2F2019%2F09%2F26%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fmysql%E4%B8%ADchar%EF%BC%8Cvarchar%2F</url>
    <content type="text"><![CDATA[MySQL中char和varcharchar长度不变，长度不足时会补空格，取出数据时也会有空格需要进行trim，存取效率要高，英文1字节，汉字2字节 varchar 长度不定，如果长度不足，长度会自动转换，更节省空间，英文汉字都是2字节]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello Hexo]]></title>
    <url>%2F2018%2F03%2F23%2FHello-Hexo%2F</url>
    <content type="text"><![CDATA[This is my first test on githubBlog by hexo.]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F03%2F23%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>Web</tag>
      </tags>
  </entry>
</search>
